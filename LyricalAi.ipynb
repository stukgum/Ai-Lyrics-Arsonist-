{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPM0aupzs4GArVAGIDMNl5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bca83b71a3f047869f063b06e70a4c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42b53698136e4a41b086b96f700e30a4",
              "IPY_MODEL_e1d63c0cdf6445d59bddaba840e4beb5",
              "IPY_MODEL_6b3a94bf5bc3410b8cfd415335132db1"
            ],
            "layout": "IPY_MODEL_8213a790cbe94030b4cb1f247b25fa04"
          }
        },
        "42b53698136e4a41b086b96f700e30a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cbbf3a53c94b6f888cf5b0598bd95d",
            "placeholder": "​",
            "style": "IPY_MODEL_36e931cb5af94d7b802602625b5fba50",
            "value": "config.json: 100%"
          }
        },
        "e1d63c0cdf6445d59bddaba840e4beb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e82a86174d64941b13c29bb01eebbad",
            "max": 762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9733b528014d4e0b8b8f1d6576a8a8a9",
            "value": 762
          }
        },
        "6b3a94bf5bc3410b8cfd415335132db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e49eeca62d4b0fb29032079c0688a5",
            "placeholder": "​",
            "style": "IPY_MODEL_2f26d0e5e7db4067829d11660166f5d3",
            "value": " 762/762 [00:00&lt;00:00, 86.0kB/s]"
          }
        },
        "8213a790cbe94030b4cb1f247b25fa04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cbbf3a53c94b6f888cf5b0598bd95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e931cb5af94d7b802602625b5fba50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e82a86174d64941b13c29bb01eebbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9733b528014d4e0b8b8f1d6576a8a8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26e49eeca62d4b0fb29032079c0688a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f26d0e5e7db4067829d11660166f5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db086c68716847e4a99437fe10b7534d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7303a3789e06478395351c8f76f7d01a",
              "IPY_MODEL_9eb6072f61664581b00043da9dc8b0aa",
              "IPY_MODEL_b5aa568edf884aa8950d599f3f78a8f8"
            ],
            "layout": "IPY_MODEL_d6c23d0a89044327a1aea61ce8dd3113"
          }
        },
        "7303a3789e06478395351c8f76f7d01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88f2b8e307242d78d9ece874c6df44a",
            "placeholder": "​",
            "style": "IPY_MODEL_88317d4f150c4f628e018710ae2b9d76",
            "value": "model.safetensors: 100%"
          }
        },
        "9eb6072f61664581b00043da9dc8b0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_581635b92c764a148f33b0cdfb4b1285",
            "max": 352824413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af90bb4a27044bdf97f265fb3ff180bf",
            "value": 352824413
          }
        },
        "b5aa568edf884aa8950d599f3f78a8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6305eed6c9e404c89de6a6c0e9d8e52",
            "placeholder": "​",
            "style": "IPY_MODEL_73db298c3dce491ebb8a8072179c210b",
            "value": " 353M/353M [00:05&lt;00:00, 56.1MB/s]"
          }
        },
        "d6c23d0a89044327a1aea61ce8dd3113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88f2b8e307242d78d9ece874c6df44a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88317d4f150c4f628e018710ae2b9d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "581635b92c764a148f33b0cdfb4b1285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af90bb4a27044bdf97f265fb3ff180bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6305eed6c9e404c89de6a6c0e9d8e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73db298c3dce491ebb8a8072179c210b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1abfd5648e14a85905818272e35b9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e60667f34cc7460180a9d2721ebcd050",
              "IPY_MODEL_ce3530a7faba4042aaf8a2ddeba9c812",
              "IPY_MODEL_e505406e418e403b889df999e1c4ff91"
            ],
            "layout": "IPY_MODEL_09e9b28d8c1d41dbb42988dc31e88919"
          }
        },
        "e60667f34cc7460180a9d2721ebcd050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a8a8eaf656b4dd69cabad5047154fe5",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c5d2aac5414011bd4147ebf88cfb03",
            "value": "generation_config.json: 100%"
          }
        },
        "ce3530a7faba4042aaf8a2ddeba9c812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eca9d6df74748e487c60afb4bc96282",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_420d3e7574664cdfaaad113f4d2db13a",
            "value": 124
          }
        },
        "e505406e418e403b889df999e1c4ff91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e10de7270941c2a81d646ff813b609",
            "placeholder": "​",
            "style": "IPY_MODEL_f8ad91b986a14c5a9b36ee4e053f32c7",
            "value": " 124/124 [00:00&lt;00:00, 9.52kB/s]"
          }
        },
        "09e9b28d8c1d41dbb42988dc31e88919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a8a8eaf656b4dd69cabad5047154fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c5d2aac5414011bd4147ebf88cfb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eca9d6df74748e487c60afb4bc96282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420d3e7574664cdfaaad113f4d2db13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2e10de7270941c2a81d646ff813b609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ad91b986a14c5a9b36ee4e053f32c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48124b12bee44b8cb02c88a356129db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2039bf12257141c595d03cd451083f93",
              "IPY_MODEL_2b388487ba40484ea8bd4c6a6acc90a9",
              "IPY_MODEL_4e20fe5c910d4ee09f0ce2bbe2606e5f"
            ],
            "layout": "IPY_MODEL_2dfcd5016a154714b7c83df0ca406d50"
          }
        },
        "2039bf12257141c595d03cd451083f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca13ff16193409d8fddd4cd019695ac",
            "placeholder": "​",
            "style": "IPY_MODEL_4b1bfc029bf34246be1130541e3aeec3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2b388487ba40484ea8bd4c6a6acc90a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ff5090cdfac4ac3b5c06f2c7b7f186d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4126864d2c304847b5921a6577576379",
            "value": 26
          }
        },
        "4e20fe5c910d4ee09f0ce2bbe2606e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c47c296bbc649f3a39863bc27af5a52",
            "placeholder": "​",
            "style": "IPY_MODEL_f080edf43f084ebf85c5b1bb2b922abf",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.26kB/s]"
          }
        },
        "2dfcd5016a154714b7c83df0ca406d50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca13ff16193409d8fddd4cd019695ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1bfc029bf34246be1130541e3aeec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ff5090cdfac4ac3b5c06f2c7b7f186d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4126864d2c304847b5921a6577576379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c47c296bbc649f3a39863bc27af5a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f080edf43f084ebf85c5b1bb2b922abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40f225881b524cc99c80e79f3b97329d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2f42f3233b94a589a3b99d4752d4e1d",
              "IPY_MODEL_d75f7bd55a2d4b4db760329aac98d741",
              "IPY_MODEL_096998e26e34492baa6f00941855a4b6"
            ],
            "layout": "IPY_MODEL_d1cce53d24b54238bd3c91b41a8b48fd"
          }
        },
        "c2f42f3233b94a589a3b99d4752d4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f700b40c2ee34ed1ad9ee0986105464a",
            "placeholder": "​",
            "style": "IPY_MODEL_f852e22218ec43cdb9280271684fd012",
            "value": "vocab.json: 100%"
          }
        },
        "d75f7bd55a2d4b4db760329aac98d741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74160a1e6e2b4c61a22ff7feaa1ca6f4",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1275019ce4cd4fca9299e5f46551ebf4",
            "value": 1042301
          }
        },
        "096998e26e34492baa6f00941855a4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066ccf83840c4bf2b86a90e01a3597dd",
            "placeholder": "​",
            "style": "IPY_MODEL_dcbf5d9fd1fe470c93fd2a204caad987",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 13.9MB/s]"
          }
        },
        "d1cce53d24b54238bd3c91b41a8b48fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f700b40c2ee34ed1ad9ee0986105464a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f852e22218ec43cdb9280271684fd012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74160a1e6e2b4c61a22ff7feaa1ca6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1275019ce4cd4fca9299e5f46551ebf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "066ccf83840c4bf2b86a90e01a3597dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbf5d9fd1fe470c93fd2a204caad987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30dad2eef7e24187a984061b2866c749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc6a2aac873947d7940532839a0dc8ea",
              "IPY_MODEL_837ef3c3c78f4afd97fddf123a2dd759",
              "IPY_MODEL_626f20676e0d4e448ff2d11a010a11b3"
            ],
            "layout": "IPY_MODEL_5aa62390ec7c45f28691bd6247530126"
          }
        },
        "cc6a2aac873947d7940532839a0dc8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab859ca5c914a2197342f69e28963fd",
            "placeholder": "​",
            "style": "IPY_MODEL_b3fcc8f35d8846fb9638885e5e0b2f25",
            "value": "merges.txt: 100%"
          }
        },
        "837ef3c3c78f4afd97fddf123a2dd759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b235f81eec9943f8b5a553397d93996d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f91d9de8f3b44dfaf59103d91b09d70",
            "value": 456318
          }
        },
        "626f20676e0d4e448ff2d11a010a11b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19347114fc4f46809e58562efa99f0c5",
            "placeholder": "​",
            "style": "IPY_MODEL_9f0504703a0a4b9abef79c5a63938e13",
            "value": " 456k/456k [00:00&lt;00:00, 7.20MB/s]"
          }
        },
        "5aa62390ec7c45f28691bd6247530126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab859ca5c914a2197342f69e28963fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fcc8f35d8846fb9638885e5e0b2f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b235f81eec9943f8b5a553397d93996d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f91d9de8f3b44dfaf59103d91b09d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19347114fc4f46809e58562efa99f0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0504703a0a4b9abef79c5a63938e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de6da14316841c594a9875d9ac18844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cce60a8b05d4884be5db58e9cf58ce1",
              "IPY_MODEL_a11788d3620c4b4696ae587f475294fc",
              "IPY_MODEL_6f319be244d540cebc4a73d1a3251654"
            ],
            "layout": "IPY_MODEL_b98a2e7aeb4c4e7db902378b099a826f"
          }
        },
        "8cce60a8b05d4884be5db58e9cf58ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e4fe8831d34f57ac1b32e852dd282a",
            "placeholder": "​",
            "style": "IPY_MODEL_f7babd89ac6c414dbc5d71ffcab0dcbd",
            "value": "tokenizer.json: 100%"
          }
        },
        "a11788d3620c4b4696ae587f475294fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6148909621745d1a0118deaceb7deb6",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7714859d45d243fda6490977bf4eb278",
            "value": 1355256
          }
        },
        "6f319be244d540cebc4a73d1a3251654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b49cd25a2f4e45bf62086657cdb565",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dc9ee92a974a179fd081fb1cc27763",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "b98a2e7aeb4c4e7db902378b099a826f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e4fe8831d34f57ac1b32e852dd282a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7babd89ac6c414dbc5d71ffcab0dcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6148909621745d1a0118deaceb7deb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7714859d45d243fda6490977bf4eb278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8b49cd25a2f4e45bf62086657cdb565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dc9ee92a974a179fd081fb1cc27763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stukgum/Ai-Lyrics-Arsonist-/blob/main/LyricalAi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO60VvqoXg4m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9621488e"
      },
      "source": [
        "# Task\n",
        "Develop an AI-powered app called \"Ai Lyrical Arsonist\" that generates lyrics for uploaded beats, provides synchronized playback with visuals, and allows users to record and export their performances. The app should be developed in phases, starting with a core MVP and then enhancing the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fd1fa75"
      },
      "source": [
        "## Audio Analysis Enhancement\n",
        "\n",
        "### Subtask:\n",
        "Integrate a more robust mood detection method into the audio analysis step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c359b57b"
      },
      "source": [
        "## Lyric Editing\n",
        "\n",
        "### Subtask:\n",
        "Implement basic editing features for the generated lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66af249d"
      },
      "source": [
        "## Audio Analysis Enhancement\n",
        "\n",
        "### Subtask:\n",
        "Integrate a more robust mood detection method into the audio analysis step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f873513"
      },
      "source": [
        "## Beat input handling\n",
        "\n",
        "### Subtask:\n",
        "Develop code to accept beat uploads (MP3/WAV) and process links from various sources (YouTube, SoundCloud, RapChat, RapFame, Voloco). This may involve exploring libraries for downloading audio from URLs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c0a9dac"
      },
      "source": [
        "**Reasoning**:\n",
        "Research and identify appropriate Python libraries for handling audio file uploads and downloading audio from online sources. Based on research, `pydub` is suitable for audio file handling, and `yt-dlp` is effective for downloading from various online sources including YouTube and SoundCloud. Downloading from platforms like RapChat, RapFame, and Voloco might be more complex and may require reverse engineering or dedicated APIs, which are beyond the scope of readily available libraries for general use. Therefore, I will focus on implementing handling for file uploads, YouTube, and SoundCloud using the identified libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c68eb0b1"
      },
      "source": [
        "## Lyric Editing\n",
        "\n",
        "### Subtask:\n",
        "Implement basic editing features for the generated lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3df6d588"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the existing visualizer code to make it more dynamic. Instead of a static plot of the entire audio, we will create a simple animation that updates the soundwave as the audio progresses. This will involve using `matplotlib.animation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799d041e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5646aa7b-b7d2-4e05-8d91-20574eb84f50"
      },
      "source": [
        "# We'll need to reinstall ffmpeg for the animation saving\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.animation as animation\n",
        "import threading\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import os # Import the os module\n",
        "\n",
        "# Assume processed_audio_path and sr are available from previous steps\n",
        "# If not, define them for demonstration purposes.\n",
        "if 'processed_audio_path' not in locals() or not os.path.exists(processed_audio_path):\n",
        "    processed_audio_path = 'processed_audio/downloaded_audio.wav' # Placeholder\n",
        "    # Create a dummy file if it doesn't exist for demonstration\n",
        "    if not os.path.exists('processed_audio'):\n",
        "        os.makedirs('processed_audio')\n",
        "    if not os.path.exists(processed_audio_path):\n",
        "        import soundfile as sf\n",
        "        samplerate = 22050\n",
        "        duration = 10\n",
        "        data = np.zeros(duration * samplerate)\n",
        "        sf.write(processed_audio_path, data, samplerate)\n",
        "        print(f\"Created a dummy WAV file at: {processed_audio_path}\")\n",
        "\n",
        "\n",
        "# Load the audio file\n",
        "try:\n",
        "    y, sr = librosa.load(processed_audio_path)\n",
        "    audio_duration_s = librosa.get_duration(y=y, sr=sr)\n",
        "    print(f\"Successfully loaded audio file from {processed_audio_path}\")\n",
        "    print(f\"Audio duration: {audio_duration_s:.2f} seconds\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file for visualizer: {e}\")\n",
        "    y, sr = None, None\n",
        "    audio_duration_s = 0\n",
        "\n",
        "if y is not None and sr is not None:\n",
        "    # Calculate RMS energy over small frames\n",
        "    frame_length = 2048 # You can adjust this\n",
        "    hop_length = 512   # You can adjust this\n",
        "    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    rms_times = librosa.times_like(rms, sr=sr, hop_length=hop_length)\n",
        "\n",
        "    # Set up the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    line, = ax.plot([], [], lw=2)\n",
        "    ax.set_ylim(0, rms.max() * 1.1)\n",
        "    ax.set_xlim(0, audio_duration_s)\n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(\"RMS Energy\")\n",
        "    ax.set_title(\"Dynamic Soundwave Visualizer\")\n",
        "    plt.close(fig) # Prevent the initial static plot from displaying\n",
        "\n",
        "    # Function to update the plot for each frame\n",
        "    def update(frame):\n",
        "        # 'frame' here will represent the current time in seconds\n",
        "        # Find the index in rms_times that is closest to the current frame time\n",
        "        closest_time_index = np.argmin(np.abs(rms_times - frame))\n",
        "\n",
        "        # Update the data for the line plot up to the current time\n",
        "        line.set_data(rms_times[:closest_time_index+1], rms[:closest_time_index+1])\n",
        "\n",
        "        # You might want to adjust the x-axis view window to follow the playback\n",
        "        # For now, we'll keep the x-axis fixed to show the entire duration.\n",
        "        # ax.set_xlim(max(0, frame - 5), min(audio_duration_s, frame + 5)) # Example of sliding window\n",
        "\n",
        "        return line,\n",
        "\n",
        "    # Function to simulate audio playback and provide current time\n",
        "    def play_audio_and_sync(audio_path):\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"Audio file not found for playback: {audio_path}\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            audio_segment = AudioSegment.from_wav(audio_path)\n",
        "            audio_duration_ms = len(audio_segment)\n",
        "            start_time = time.time()\n",
        "            print(\"Starting audio playback for synchronization...\")\n",
        "            play(audio_segment) # This is blocking\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during audio playback for synchronization: {e}\")\n",
        "\n",
        "\n",
        "    # Use a shared variable to track elapsed time\n",
        "    elapsed_time = 0\n",
        "    is_playing = False\n",
        "\n",
        "    def update_elapsed_time():\n",
        "        global elapsed_time, is_playing\n",
        "        is_playing = True\n",
        "        start_time = time.time()\n",
        "        while is_playing and elapsed_time < audio_duration_s:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            time.sleep(0.05) # Update every 50 ms\n",
        "\n",
        "        is_playing = False\n",
        "        elapsed_time = audio_duration_s # Ensure it reaches the end\n",
        "\n",
        "\n",
        "    # Create and start the thread to update elapsed time\n",
        "    time_thread = threading.Thread(target=update_elapsed_time)\n",
        "    time_thread.start()\n",
        "\n",
        "    # Create and start the audio playback thread\n",
        "    audio_playback_thread = threading.Thread(target=play_audio_and_sync, args=(processed_audio_path,))\n",
        "    audio_playback_thread.start()\n",
        "\n",
        "\n",
        "    # Function to get the current time for the animation frame\n",
        "    def get_current_time():\n",
        "        while elapsed_time < audio_duration_s or is_playing:\n",
        "            yield elapsed_time\n",
        "        yield audio_duration_s # Ensure the last frame is shown\n",
        "\n",
        "    # Create the animation\n",
        "    # We use frames=get_current_time() to drive the animation by the elapsed time\n",
        "    ani = animation.FuncAnimation(fig, update, frames=get_current_time, blit=True, interval=50, repeat=False) # interval in ms\n",
        "\n",
        "    print(\"Displaying dynamic soundwave visualizer...\")\n",
        "    plt.show()\n",
        "\n",
        "    # Wait for the audio playback and time threads to finish\n",
        "    audio_playback_thread.join()\n",
        "    time_thread.join()\n",
        "    print(\"Dynamic visualizer and playback finished.\")\n",
        "\n",
        "else:\n",
        "    print(\"Audio data not available, cannot generate dynamic soundwave visualizer.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Created a dummy WAV file at: processed_audio/downloaded_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded audio file from processed_audio/downloaded_audio.wav\n",
            "Audio duration: 10.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2084223563.py:52: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  ax.set_ylim(0, rms.max() * 1.1)\n",
            "/tmp/ipython-input-2084223563.py:124: UserWarning: frames=<function get_current_time at 0x7e4c70991e40> which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
            "  ani = animation.FuncAnimation(fig, update, frames=get_current_time, blit=True, interval=50, repeat=False) # interval in ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting audio playback for synchronization...\n",
            "Displaying dynamic soundwave visualizer...\n",
            "Dynamic visualizer and playback finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1589c151"
      },
      "source": [
        "## Lyric Editing\n",
        "\n",
        "### Subtask:\n",
        "Implement basic editing features for the generated lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6c55e7"
      },
      "source": [
        "**Reasoning**:\n",
        "I will provide a simple text area where users can view and edit the generated lyrics. This can be implemented using an HTML form within a Flask route, similar to the audio input handling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2037cd3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a47100-c9b7-4658-d561-1a7d0583030d"
      },
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "\n",
        "# Assume 'final_generated_lyrics' is available from the previous step\n",
        "# If not, use a placeholder for demonstration.\n",
        "if 'final_generated_lyrics' not in locals() or not final_generated_lyrics:\n",
        "    final_generated_lyrics = \"\"\"\n",
        "    (Verse 1)\n",
        "    This is a placeholder lyric,\n",
        "    Ready for you to edit it quick.\n",
        "    (Chorus)\n",
        "    Change these lines, make them shine,\n",
        "    Your creativity, truly divine.\n",
        "    \"\"\"\n",
        "    print(\"Using placeholder lyrics for the editing step.\")\n",
        "\n",
        "# Simple Flask app setup for lyric editing (can be integrated with the main app later)\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/edit_lyrics', methods=['GET', 'POST'])\n",
        "def edit_lyrics():\n",
        "    global final_generated_lyrics # Update the global variable for demonstration\n",
        "    edited_lyrics = final_generated_lyrics\n",
        "    if request.method == 'POST':\n",
        "        edited_lyrics = request.form.get('lyrics_textarea', '')\n",
        "        # In a real application, you would save the edited_lyrics\n",
        "        print(\"Lyrics edited and submitted:\")\n",
        "        print(edited_lyrics)\n",
        "        # You might want to redirect to another page or update a global variable\n",
        "        # For now, we just print and the page will show the edited lyrics\n",
        "        final_generated_lyrics = edited_lyrics\n",
        "\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Edit Lyrics</title>\n",
        "    <h1>Edit Your Lyrics</h1>\n",
        "    <form method=post>\n",
        "      <textarea name=\"lyrics_textarea\" rows=\"20\" cols=\"80\">{{ lyrics }}</textarea><br><br>\n",
        "      <input type=submit value=Save>\n",
        "    </form>\n",
        "    ''', lyrics=edited_lyrics)\n",
        "\n",
        "# To run this example Flask app route, you would typically add it to your main Flask app instance\n",
        "# and run the app.\n",
        "\n",
        "# Example of how you might run this specific route for testing (requires running the Flask app)\n",
        "# from werkzeug.serving import run_simple\n",
        "# run_simple('localhost', 5000, app) # This will run the Flask app and make it accessible"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using placeholder lyrics for the editing step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c94097c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code cell defined a Flask route for lyric editing. Now I will provide instructions on how to run the Flask application to access this editing interface. This involves adding the standard Flask run block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2c6ce04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea39c44-90b6-4c68-832d-b7146702b8a1"
      },
      "source": [
        "# To run the Flask app (for demonstration purposes)\n",
        "# Note: In a Colab environment, you might need to use ngrok or a similar service\n",
        "# to expose your local Flask server to the internet for testing in a browser.\n",
        "# For simple testing within Colab, you can use the built-in preview.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This will run the Flask development server\n",
        "    # debug=True allows for automatic reloading and helpful error pages\n",
        "    # Set host='0.0.0.0' to make the server accessible externally if needed (e.g., for ngrok)\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08603437"
      },
      "source": [
        "## Visualizer Enhancement and Editing\n",
        "\n",
        "### Subtask:\n",
        "Enhance the soundwave visualizer to be more dynamic and responsive to the audio. Implement basic editing features for the generated lyrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e8e6963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "782c2d3b-180e-46e3-81f6-d4097e687fd0"
      },
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from flask import Flask, request, render_template_string, redirect, url_for\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "# Define allowed file types for upload\n",
        "ALLOWED_EXTENSIONS = {'mp3', 'wav'}\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def process_audio_input(input_source):\n",
        "    \"\"\"\n",
        "    Processes audio input from either a file upload or a URL.\n",
        "\n",
        "    Args:\n",
        "        input_source: Either a file storage object (from Flask request.files) or a string URL.\n",
        "\n",
        "    Returns:\n",
        "        The path to the processed WAV file, or None if processing failed.\n",
        "    \"\"\"\n",
        "    output_dir = 'processed_audio'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    if hasattr(input_source, 'filename'):  # Handle file upload\n",
        "        if input_source and allowed_file(input_source.filename):\n",
        "            filename = secure_filename(input_source.filename)\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            input_source.save(filepath)\n",
        "            try:\n",
        "                audio = AudioSegment.from_file(filepath)\n",
        "                wav_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.wav')\n",
        "                audio.export(wav_path, format='wav')\n",
        "                os.remove(filepath) # Clean up the original uploaded file\n",
        "                return wav_path\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing uploaded audio file: {e}\")\n",
        "                os.remove(filepath)\n",
        "                return None\n",
        "        else:\n",
        "            print(\"Invalid file type or no file uploaded.\")\n",
        "            return None\n",
        "    elif isinstance(input_source, str): # Handle URL\n",
        "        url = input_source\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'wav',\n",
        "                }],\n",
        "                'outtmpl': os.path.join(output_dir, '%(title)s.%(ext)s'),\n",
        "                'extract_flat': True,\n",
        "                'noplaylist': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(url, download=False)\n",
        "                if 'entries' in info_dict: # Handle playlists, although we set noplaylist=True, some URLs might be interpreted as playlists\n",
        "                    info_dict = info_dict['entries'][0] # Take the first video\n",
        "                title = info_dict.get('title', 'downloaded_audio')\n",
        "                output_filename = os.path.join(output_dir, f\"{title}.wav\")\n",
        "                ydl.download([url])\n",
        "                return output_filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio from URL: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Invalid input source.\")\n",
        "        return None\n",
        "\n",
        "# Example Flask app setup for demonstration (can be adapted for the final application)\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads' # Not strictly needed with the current logic, but good practice\n",
        "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_or_download():\n",
        "    processed_file = None\n",
        "    if request.method == 'POST':\n",
        "        if 'audio_file' in request.files:\n",
        "            audio_file = request.files['audio_file']\n",
        "            processed_file = process_audio_input(audio_file)\n",
        "        elif 'audio_url' in request.form:\n",
        "            audio_url = request.form['audio_url']\n",
        "            processed_file = process_audio_input(audio_url)\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Upload or Download Audio</title>\n",
        "    <h1>Upload an audio file or provide a URL</h1>\n",
        "    <form method=post enctype=multipart/form-data>\n",
        "      <p><input type=file name=audio_file>\n",
        "         <input type=submit value=Upload>\n",
        "    </form>\n",
        "    <form method=post>\n",
        "      <p><input type=text name=audio_url placeholder=\"Enter URL\">\n",
        "         <input type=submit value=Download>\n",
        "    </form>\n",
        "    {% if processed_file %}\n",
        "    <h2>Processed Audio:</h2>\n",
        "    <p>File saved at: {{ processed_file }}</p>\n",
        "    {% endif %}\n",
        "    ''', processed_file=processed_file)\n",
        "\n",
        "# To run this example Flask app, you would typically use:\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'yt_dlp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-743625421.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myt_dlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_template_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwerkzeug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msecure_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yt_dlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "715e82cd",
        "outputId": "0c9c085c-880a-4d64-cd28-0668d9e3ad9a"
      },
      "source": [
        "!pip install yt-dlp pydub Flask\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.9.5-py3-none-any.whl.metadata (177 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.3)\n",
            "Downloading yt_dlp-2025.9.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m143.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.9.5\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,008 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,281 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,496 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,798 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,691 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [71.0 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,581 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,327 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.1 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,642 kB]\n",
            "Fetched 35.7 MB in 3s (11.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549,
          "referenced_widgets": [
            "bca83b71a3f047869f063b06e70a4c9e",
            "42b53698136e4a41b086b96f700e30a4",
            "e1d63c0cdf6445d59bddaba840e4beb5",
            "6b3a94bf5bc3410b8cfd415335132db1",
            "8213a790cbe94030b4cb1f247b25fa04",
            "c7cbbf3a53c94b6f888cf5b0598bd95d",
            "36e931cb5af94d7b802602625b5fba50",
            "4e82a86174d64941b13c29bb01eebbad",
            "9733b528014d4e0b8b8f1d6576a8a8a9",
            "26e49eeca62d4b0fb29032079c0688a5",
            "2f26d0e5e7db4067829d11660166f5d3",
            "db086c68716847e4a99437fe10b7534d",
            "7303a3789e06478395351c8f76f7d01a",
            "9eb6072f61664581b00043da9dc8b0aa",
            "b5aa568edf884aa8950d599f3f78a8f8",
            "d6c23d0a89044327a1aea61ce8dd3113",
            "b88f2b8e307242d78d9ece874c6df44a",
            "88317d4f150c4f628e018710ae2b9d76",
            "581635b92c764a148f33b0cdfb4b1285",
            "af90bb4a27044bdf97f265fb3ff180bf",
            "f6305eed6c9e404c89de6a6c0e9d8e52",
            "73db298c3dce491ebb8a8072179c210b",
            "a1abfd5648e14a85905818272e35b9a2",
            "e60667f34cc7460180a9d2721ebcd050",
            "ce3530a7faba4042aaf8a2ddeba9c812",
            "e505406e418e403b889df999e1c4ff91",
            "09e9b28d8c1d41dbb42988dc31e88919",
            "6a8a8eaf656b4dd69cabad5047154fe5",
            "c4c5d2aac5414011bd4147ebf88cfb03",
            "4eca9d6df74748e487c60afb4bc96282",
            "420d3e7574664cdfaaad113f4d2db13a",
            "d2e10de7270941c2a81d646ff813b609",
            "f8ad91b986a14c5a9b36ee4e053f32c7",
            "48124b12bee44b8cb02c88a356129db2",
            "2039bf12257141c595d03cd451083f93",
            "2b388487ba40484ea8bd4c6a6acc90a9",
            "4e20fe5c910d4ee09f0ce2bbe2606e5f",
            "2dfcd5016a154714b7c83df0ca406d50",
            "4ca13ff16193409d8fddd4cd019695ac",
            "4b1bfc029bf34246be1130541e3aeec3",
            "8ff5090cdfac4ac3b5c06f2c7b7f186d",
            "4126864d2c304847b5921a6577576379",
            "5c47c296bbc649f3a39863bc27af5a52",
            "f080edf43f084ebf85c5b1bb2b922abf",
            "40f225881b524cc99c80e79f3b97329d",
            "c2f42f3233b94a589a3b99d4752d4e1d",
            "d75f7bd55a2d4b4db760329aac98d741",
            "096998e26e34492baa6f00941855a4b6",
            "d1cce53d24b54238bd3c91b41a8b48fd",
            "f700b40c2ee34ed1ad9ee0986105464a",
            "f852e22218ec43cdb9280271684fd012",
            "74160a1e6e2b4c61a22ff7feaa1ca6f4",
            "1275019ce4cd4fca9299e5f46551ebf4",
            "066ccf83840c4bf2b86a90e01a3597dd",
            "dcbf5d9fd1fe470c93fd2a204caad987",
            "30dad2eef7e24187a984061b2866c749",
            "cc6a2aac873947d7940532839a0dc8ea",
            "837ef3c3c78f4afd97fddf123a2dd759",
            "626f20676e0d4e448ff2d11a010a11b3",
            "5aa62390ec7c45f28691bd6247530126",
            "3ab859ca5c914a2197342f69e28963fd",
            "b3fcc8f35d8846fb9638885e5e0b2f25",
            "b235f81eec9943f8b5a553397d93996d",
            "4f91d9de8f3b44dfaf59103d91b09d70",
            "19347114fc4f46809e58562efa99f0c5",
            "9f0504703a0a4b9abef79c5a63938e13",
            "2de6da14316841c594a9875d9ac18844",
            "8cce60a8b05d4884be5db58e9cf58ce1",
            "a11788d3620c4b4696ae587f475294fc",
            "6f319be244d540cebc4a73d1a3251654",
            "b98a2e7aeb4c4e7db902378b099a826f",
            "61e4fe8831d34f57ac1b32e852dd282a",
            "f7babd89ac6c414dbc5d71ffcab0dcbd",
            "d6148909621745d1a0118deaceb7deb6",
            "7714859d45d243fda6490977bf4eb278",
            "c8b49cd25a2f4e45bf62086657cdb565",
            "e0dc9ee92a974a179fd081fb1cc27763"
          ]
        },
        "id": "3a72b142",
        "outputId": "3159e779-6e08-47c5-b9af-bd23a0137bca"
      },
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from flask import Flask, request, render_template_string, redirect, url_for, send_file\n",
        "from werkzeug.utils import secure_filename\n",
        "import librosa\n",
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "import scipy.io.wavfile as wav\n",
        "import time\n",
        "import threading\n",
        "from transformers import pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "# Instantiate a single Flask application\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads'\n",
        "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
        "os.makedirs('processed_audio', exist_ok=True)\n",
        "os.makedirs('user_recordings', exist_ok=True)\n",
        "os.makedirs('final_mixes', exist_ok=True)\n",
        "os.makedirs('visualizer_frames', exist_ok=True) # Directory to save visualizer frames\n",
        "\n",
        "\n",
        "# Global variables to share data between routes\n",
        "processed_audio_path = None\n",
        "audio_analysis_results = None\n",
        "final_generated_lyrics = None\n",
        "generator = None # Language model generator instance\n",
        "audio_duration_s = 0 # To store audio duration for visualization\n",
        "\n",
        "# Initialize the language model (can be done once at the start)\n",
        "try:\n",
        "    # Use a smaller model for potentially faster loading in Colab\n",
        "    generator = pipeline('text-generation', model='distilgpt2')\n",
        "    print(\"Successfully loaded distilgpt2 model for text generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading language model: {e}\")\n",
        "    generator = None\n",
        "\n",
        "\n",
        "# Define allowed file types for upload\n",
        "ALLOWED_EXTENSIONS = {'mp3', 'wav'}\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def process_audio_input(input_source):\n",
        "    \"\"\"\n",
        "    Processes audio input from either a file upload or a URL.\n",
        "\n",
        "    Args:\n",
        "        input_source: Either a file storage object (from Flask request.files) or a string URL.\n",
        "\n",
        "    Returns:\n",
        "        The path to the processed WAV file, or None if processing failed.\n",
        "    \"\"\"\n",
        "    output_dir = 'processed_audio'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    if hasattr(input_source, 'filename'):  # Handle file upload\n",
        "        if input_source and allowed_file(input_source.filename):\n",
        "            filename = secure_filename(input_source.filename)\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            input_source.save(filepath)\n",
        "            try:\n",
        "                audio = AudioSegment.from_file(filepath)\n",
        "                wav_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.wav')\n",
        "                audio.export(wav_path, format='wav')\n",
        "                os.remove(filepath) # Clean up the original uploaded file\n",
        "                return wav_path\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing uploaded audio file: {e}\")\n",
        "                os.remove(filepath)\n",
        "                return None\n",
        "        else:\n",
        "            print(\"Invalid file type or no file uploaded.\")\n",
        "            return None\n",
        "    elif isinstance(input_source, str): # Handle URL\n",
        "        url = input_source\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'wav',\n",
        "                }],\n",
        "                'outtmpl': os.path.join(output_dir, '%(title)s.%(ext)s'),\n",
        "                'extract_flat': True,\n",
        "                'noplaylist': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(url, download=False)\n",
        "                if 'entries' in info_dict: # Handle playlists, although we set noplaylist=True, some URLs might be interpreted as playlists\n",
        "                    info_dict = info_dict['entries'][0] # Take the first video\n",
        "                title = info_dict.get('title', 'downloaded_audio')\n",
        "                output_filename = os.path.join(output_dir, f\"{title}.wav\")\n",
        "                ydl.download([url])\n",
        "                return output_filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio from URL: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Invalid input source.\")\n",
        "        return None\n",
        "\n",
        "def analyze_audio(audio_path):\n",
        "    \"\"\"Analyzes audio to detect BPM, tempo, and mood.\"\"\"\n",
        "    global audio_duration_s\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"Audio file not found for analysis: {audio_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path)\n",
        "        audio_duration_s = librosa.get_duration(y=y, sr=sr)\n",
        "        print(f\"Successfully loaded audio file for analysis: {audio_path}\")\n",
        "        print(f\"Audio duration: {audio_duration_s:.2f} seconds\")\n",
        "\n",
        "\n",
        "        # Calculate BPM and tempo\n",
        "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "        print(f\"Estimated BPM: {tempo:.2f}\")\n",
        "\n",
        "        # Simple heuristic for mood (highly simplified for demonstration)\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "        mean_centroid = np.mean(spectral_centroids)\n",
        "        mean_zcr = np.mean(zcr)\n",
        "\n",
        "        estimated_mood = \"Neutral\"\n",
        "        if tempo > 120 and mean_centroid > 2000:\n",
        "            estimated_mood = \"Energetic/Happy\"\n",
        "        elif tempo < 80 and mean_centroid < 1500:\n",
        "             estimated_mood = \"Calm/Sad\"\n",
        "        elif tempo > 140 and mean_zcr > 0.1:\n",
        "             estimated_mood = \"Fast/Intense\"\n",
        "\n",
        "        print(f\"Estimated Mood (Simplified Heuristic): {estimated_mood}\")\n",
        "\n",
        "        return {\n",
        "            'bpm': tempo,\n",
        "            'tempo': tempo,\n",
        "            'estimated_mood': estimated_mood,\n",
        "            'duration': audio_duration_s,\n",
        "            'y': y, # Store audio time series data for visualizer\n",
        "            'sr': sr  # Store sampling rate for visualizer\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during audio analysis: {e}\")\n",
        "        audio_duration_s = 0\n",
        "        return None\n",
        "\n",
        "def create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"\n",
        "    Creates a prompt string for the language model based on audio features and user inputs,\n",
        "    with enhanced genre-specific guidance.\n",
        "    \"\"\"\n",
        "    prompt = f\"Generate lyrics for a song. \"\n",
        "\n",
        "    genre_instructions = {\n",
        "        \"Hip Hop\": \"Focus on rhythm, rhyme schemes (like AABB, ABAB), wordplay, and storytelling. Use urban vocabulary. Include ad-libs.\",\n",
        "        \"Pop\": \"Write catchy melodies and simple, relatable themes. Use a verse-chorus structure. Keep language accessible.\",\n",
        "        \"Rock\": \"Incorporate powerful imagery, emotional themes, and potentially a bridge section. Can be introspective or rebellious.\",\n",
        "        \"Blues\": \"Express feelings of sadness, hardship, or sometimes resilience. Use a typical AAB lyrical structure within verses. Include themes of struggle, love, or loss.\",\n",
        "        \"Country\": \"Tell a story, often set in rural or small-town environments. Themes of love, loss, hard work, and everyday life. Use straightforward language and relatable scenarios.\",\n",
        "        \"Electronic\": \"Lyrics can be repetitive or sparse, focusing on mood and atmosphere. Themes might be abstract, futuristic, or focused on the party/dance experience.\",\n",
        "        \"R&B\": \"Focus on smooth melodies and emotional expression, often about love, relationships, or desire. Use vocal runs and ad-libs.\",\n",
        "        \"Reggae\": \"Incorporate themes of peace, love, social justice, and spirituality. Use a relaxed rhythm and potentially Jamaican Patois influences.\",\n",
        "        \"Jazz\": \"Lyrics can be improvisational or tell complex stories. Focus on mood and atmosphere, often with themes of love, city life, or introspection.\",\n",
        "        \"Folk\": \"Tell a story, often with simple melodies and acoustic instrumentation in mind. Themes of nature, history, social issues, or personal journeys.\",\n",
        "    }\n",
        "\n",
        "    if user_genre and user_genre in genre_instructions:\n",
        "        prompt += f\"The genre is {user_genre}. {genre_instructions[user_genre]} \"\n",
        "    elif user_genre:\n",
        "        prompt += f\"The genre is {user_genre}. Write lyrics appropriate for this genre. \"\n",
        "\n",
        "    if user_theme:\n",
        "        prompt += f\"The theme is about {user_theme}. \"\n",
        "\n",
        "    if audio_features:\n",
        "        if audio_features.get('bpm') is not None and audio_features['bpm'] > 0:\n",
        "             if audio_features['bpm'] < 80:\n",
        "                 prompt += \"The beat is slow, the lyrics should have a relaxed flow and longer phrases. \"\n",
        "             elif audio_features['bpm'] < 120:\n",
        "                 prompt += \"The beat has a moderate pace, the lyrics can have a balanced flow. \"\n",
        "             else:\n",
        "                 prompt += \"The beat is fast and energetic, the lyrics should match the rhythm with shorter, punchier lines. \"\n",
        "\n",
        "        if audio_features.get('estimated_mood'):\n",
        "            prompt += f\"The mood of the music is {audio_features['estimated_mood']}. The lyrics should reflect this mood. \"\n",
        "\n",
        "    if not explicit_toggle:\n",
        "        prompt += \"Avoid explicit language and sensitive topics. \"\n",
        "    else:\n",
        "        prompt += \"Explicit language is allowed. \"\n",
        "\n",
        "    prompt += \"Write the lyrics now:\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def generate_lyrics(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"Generates lyrics using the language model.\"\"\"\n",
        "    global generator\n",
        "    if generator is None:\n",
        "        print(\"Language model not loaded.\")\n",
        "        return \"Error: Language model not available.\"\n",
        "\n",
        "    if audio_features is None:\n",
        "        print(\"Audio analysis results not available.\")\n",
        "        return \"Error: Audio analysis results not available.\"\n",
        "\n",
        "    prompt = create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle)\n",
        "\n",
        "    try:\n",
        "        generated_text = generator(\n",
        "            prompt,\n",
        "            max_length=500,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            truncation=True\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        # Attempt to remove the prompt from the generated text\n",
        "        if generated_text.startswith(prompt):\n",
        "            generated_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during lyric generation: {e}\")\n",
        "        return f\"Error generating lyrics: {e}\"\n",
        "\n",
        "# Note: Recording audio directly in Flask server is not typical or recommended.\n",
        "# This function is a placeholder/demonstration. Actual recording would be client-side.\n",
        "def record_audio_dummy(filename, duration):\n",
        "    \"\"\"Creates a dummy recording file.\"\"\"\n",
        "    print(f\"Creating a dummy recording file at {filename} for {duration} seconds.\")\n",
        "    try:\n",
        "        samplerate = 44100\n",
        "        data = np.random.rand(int(duration * samplerate)) * 0.1 # Little bit of noise\n",
        "        wav.write(filename, samplerate, data)\n",
        "        print(f\"Dummy recording saved to {filename}\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating dummy recording: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def combine_audio(beat_path, vocals_path):\n",
        "    \"\"\"Combines beat audio with recorded vocals.\"\"\"\n",
        "    if not os.path.exists(beat_path):\n",
        "        return f\"Error: Beat audio file not found at {beat_path}\"\n",
        "    if not os.path.exists(vocals_path):\n",
        "        return f\"Error: Vocal audio file not found at {vocals_path}\"\n",
        "\n",
        "    try:\n",
        "        beat_audio = AudioSegment.from_wav(beat_path)\n",
        "        vocal_audio = AudioSegment.from_wav(vocals_path)\n",
        "\n",
        "        # Ensure same frame rate\n",
        "        if beat_audio.frame_rate != vocal_audio.frame_rate:\n",
        "            print(f\"Warning: Mismatch in frame rates. Resampling vocal audio from {vocal_audio.frame_rate} to {beat_audio.frame_rate}\")\n",
        "            vocal_audio = vocal_audio.set_frame_rate(beat_audio.frame_rate)\n",
        "\n",
        "        # Ensure similar length\n",
        "        min_duration = min(len(beat_audio), len(vocal_audio))\n",
        "        beat_audio = beat_audio[:min_duration]\n",
        "        vocal_audio = vocal_audio[:min_duration]\n",
        "\n",
        "        # Overlay\n",
        "        combined_audio = beat_audio.overlay(vocal_audio)\n",
        "\n",
        "        export_dir = 'final_mixes'\n",
        "        os.makedirs(export_dir, exist_ok=True)\n",
        "        final_output_path = os.path.join(export_dir, 'final_performance_mix.wav')\n",
        "        combined_audio.export(final_output_path, format=\"wav\")\n",
        "\n",
        "        return final_output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error combining audio files: {e}\")\n",
        "        return f\"Error combining audio files: {e}\"\n",
        "\n",
        "def create_soundwave_visualizer(y, sr, audio_duration_s):\n",
        "    \"\"\"Generates a static soundwave visualizer image.\"\"\"\n",
        "    if y is None or sr is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Calculate RMS energy over small frames\n",
        "        frame_length = 2048 # You can adjust this\n",
        "        hop_length = 512   # You can adjust this\n",
        "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "        rms_times = librosa.times_like(rms, sr=sr, hop_length=hop_length)\n",
        "\n",
        "        # Set up the plot\n",
        "        fig, ax = plt.subplots(figsize=(12, 4))\n",
        "        ax.plot(rms_times, rms, lw=2)\n",
        "        ax.set_ylim(0, rms.max() * 1.1)\n",
        "        ax.set_xlim(0, audio_duration_s)\n",
        "        ax.set_xlabel(\"Time (s)\")\n",
        "        ax.set_ylabel(\"RMS Energy\")\n",
        "        ax.set_title(\"Soundwave Visualizer\")\n",
        "\n",
        "        # Save plot to a bytes buffer\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        plt.close(fig) # Close the figure to free memory\n",
        "\n",
        "        # Encode image to base64\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('ascii')\n",
        "\n",
        "        return image_base64\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating soundwave visualizer: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Flask Routes\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    global processed_audio_path, audio_analysis_results, final_generated_lyrics, audio_duration_s\n",
        "    processed_file = None\n",
        "    analysis_results_display = None\n",
        "    generated_lyrics_display = None\n",
        "    visualizer_image_base64 = None\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        if 'audio_file' in request.files and request.files['audio_file'].filename != '':\n",
        "            audio_file = request.files['audio_file']\n",
        "            processed_file = process_audio_input(audio_file)\n",
        "        elif 'audio_url' in request.form and request.form['audio_url'] != '':\n",
        "            audio_url = request.form['audio_url']\n",
        "            processed_file = process_audio_input(audio_url)\n",
        "        elif 'genre' in request.form: # Handle lyric generation request\n",
        "             user_genre = request.form.get('genre', 'Hip Hop')\n",
        "             user_theme = request.form.get('theme', 'general')\n",
        "             explicit_toggle = request.form.get('explicit', 'off') == 'on'\n",
        "             if audio_analysis_results:\n",
        "                 final_generated_lyrics = generate_lyrics(audio_analysis_results, user_genre, user_theme, explicit_toggle)\n",
        "                 generated_lyrics_display = final_generated_lyrics\n",
        "             else:\n",
        "                 generated_lyrics_display = \"Please upload/process audio first to generate lyrics.\"\n",
        "\n",
        "        if processed_file:\n",
        "            processed_audio_path = processed_file\n",
        "            audio_analysis_results = analyze_audio(processed_audio_path)\n",
        "            if audio_analysis_results:\n",
        "                analysis_results_display = f\"BPM: {audio_analysis_results['bpm']:.2f}, Mood: {audio_analysis_results['estimated_mood']}, Duration: {audio_analysis_results['duration']:.2f} seconds\"\n",
        "                # Generate visualizer image immediately after analysis\n",
        "                visualizer_image_base64 = create_soundwave_visualizer(audio_analysis_results.get('y'), audio_analysis_results.get('sr'), audio_analysis_results.get('duration', 0))\n",
        "\n",
        "\n",
        "    # Display existing data on GET requests or after POST\n",
        "    if audio_analysis_results:\n",
        "         analysis_results_display = f\"BPM: {audio_analysis_results['bpm']:.2f}, Mood: {audio_analysis_results['estimated_mood']}, Duration: {audio_analysis_results['duration']:.2f} seconds\"\n",
        "         # Regenerate visualizer on page load if analysis results exist\n",
        "         visualizer_image_base64 = create_soundwave_visualizer(audio_analysis_results.get('y'), audio_analysis_results.get('sr'), audio_analysis_results.get('duration', 0))\n",
        "\n",
        "    if final_generated_lyrics:\n",
        "        generated_lyrics_display = final_generated_lyrics\n",
        "\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Ai Lyrical Arsonist</title>\n",
        "    <h1>Ai Lyrical Arsonist</h1>\n",
        "\n",
        "    <h2>Upload an audio file or provide a URL</h2>\n",
        "    <form method=post enctype=multipart/form-data>\n",
        "      <p><input type=file name=audio_file>\n",
        "         <input type=submit value=Upload File>\n",
        "    </form>\n",
        "    <form method=post>\n",
        "      <p><input type=text name=audio_url placeholder=\"Enter URL\">\n",
        "         <input type=submit value=Download URL>\n",
        "    </form>\n",
        "\n",
        "    {% if processed_audio_path %}\n",
        "    <h2>Processed Audio:</h2>\n",
        "    <p>File ready for analysis and lyric generation.</p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if analysis_results_display %}\n",
        "    <h2>Audio Analysis Results:</h2>\n",
        "    <p>{{ analysis_results_display }}</p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if visualizer_image_base64 %}\n",
        "    <h2>Soundwave Visualizer:</h2>\n",
        "    <img src=\"data:image/png;base64,{{ visualizer_image_base64 }}\" alt=\"Soundwave Visualizer\">\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    <h2>Generate Lyrics</h2>\n",
        "    <form method=post>\n",
        "      <p>Genre: <input type=text name=genre value=\"Hip Hop\"></p>\n",
        "      <p>Theme: <input type=text name=theme value=\"general\"></p>\n",
        "      <p>Explicit: <input type=checkbox name=explicit value=\"on\"></p>\n",
        "      <input type=submit value=Generate Lyrics>\n",
        "    </form>\n",
        "\n",
        "    {% if generated_lyrics_display %}\n",
        "    <h2>Generated Lyrics:</h2>\n",
        "    <pre>{{ generated_lyrics_display }}</pre>\n",
        "    <p><a href=\"{{ url_for('edit_lyrics') }}\">Edit Lyrics</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if processed_audio_path and generated_lyrics_display %}\n",
        "    <h2>Playback and Recording</h2>\n",
        "    <p><a href=\"{{ url_for('playback') }}\">Start Playback and Sync (Text-based simulation)</a></p>\n",
        "     <p><a href=\"{{ url_for('record_page') }}\">Record Performance (Client-side required for real app)</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if processed_audio_path %}\n",
        "        {% set dummy_recording_path = 'user_recordings/user_performance.wav' %}\n",
        "        {% if os.path.exists(dummy_recording_path) %}\n",
        "            <h2>Combine Audio</h2>\n",
        "            <p><a href=\"{{ url_for('combine') }}\">Combine Beat and Vocals</a></p>\n",
        "        {% else %}\n",
        "             <h2>Record Performance</h2>\n",
        "             <p>Record your performance first to enable audio combining.</p>\n",
        "              <p><a href=\"{{ url_for('record_page') }}\">Record Performance (Client-side required for real app)</a></p>\n",
        "        {% endif %}\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    {% if os.path.exists('final_mixes/final_performance_mix.wav') %}\n",
        "    <h2>Final Mix</h2>\n",
        "    <p><a href=\"{{ url_for('download_mix') }}\">Download Final Mix</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    ''', processed_audio_path=processed_audio_path,\n",
        "         analysis_results_display=analysis_analysis_results,\n",
        "         generated_lyrics_display=generated_lyrics_display,\n",
        "         visualizer_image_base64=visualizer_image_base64,\n",
        "         os=os) # Pass os to check file existence\n",
        "\n",
        "@app.route('/edit_lyrics', methods=['GET', 'POST'])\n",
        "def edit_lyrics():\n",
        "    global final_generated_lyrics\n",
        "    if request.method == 'POST':\n",
        "        final_generated_lyrics = request.form.get('lyrics_textarea', '')\n",
        "        print(\"Lyrics edited and saved.\")\n",
        "        return redirect(url_for('index')) # Redirect back to the main page\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Edit Lyrics</title>\n",
        "    <h1>Edit Your Lyrics</h1>\n",
        "    <form method=post>\n",
        "      <textarea name=\"lyrics_textarea\" rows=\"20\" cols=\"80\">{{ lyrics }}</textarea><br><br>\n",
        "      <input type=submit value=Save>\n",
        "    </form>\n",
        "    <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "    ''', lyrics=final_generated_lyrics if final_generated_lyrics else \"No lyrics generated yet.\")\n",
        "\n",
        "\n",
        "@app.route('/playback')\n",
        "def playback():\n",
        "    global processed_audio_path, final_generated_lyrics\n",
        "\n",
        "    if not processed_audio_path or not os.path.exists(processed_audio_path):\n",
        "        return \"Error: Processed audio not available.\", 400\n",
        "    if not final_generated_lyrics:\n",
        "        return \"Error: Lyrics not generated yet.\", 400\n",
        "\n",
        "    # Simple lyric synchronization strategy (as before)\n",
        "    lyrics_lines = final_generated_lyrics.strip().split('\\n')\n",
        "    try:\n",
        "        audio_segment = AudioSegment.from_wav(processed_audio_path)\n",
        "        audio_duration_ms = len(audio_segment)\n",
        "        num_lines = len(lyrics_lines)\n",
        "        line_duration_ms = audio_duration_ms / num_lines if num_lines > 0 else 0\n",
        "    except Exception as e:\n",
        "        return f\"Error loading audio for playback: {e}\", 500\n",
        "\n",
        "    # This is a simplified text-based playback simulation for the notebook environment.\n",
        "    # A real web app would require client-side JavaScript for synchronized audio and lyric display.\n",
        "    playback_output = \"Starting playback and lyric sync...\\n\"\n",
        "    for i, line in enumerate(lyrics_lines):\n",
        "        playback_output += line + \"\\n\"\n",
        "        if i < len(lyrics_lines) - 1:\n",
        "             # Simulate timing (not real-time in a Flask response)\n",
        "             pass # In a real app, this timing is handled client-side\n",
        "\n",
        "    playback_output += \"Playback and lyric display completed.\\n\"\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Playback and Sync</title>\n",
        "    <h1>Playback and Lyric Sync (Text-based simulation)</h1>\n",
        "    <pre>{{ output }}</pre>\n",
        "    <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "    ''', output=playback_output)\n",
        "\n",
        "\n",
        "@app.route('/record_page')\n",
        "def record_page():\n",
        "     # This route provides a page with instructions for recording.\n",
        "     # Actual recording is client-side in a real web app.\n",
        "     # For this demo, we'll create a dummy recording file when the user clicks 'Record Dummy'.\n",
        "     return render_template_string('''\n",
        "     <!doctype html>\n",
        "     <title>Record Performance</title>\n",
        "     <h1>Record Your Performance</h1>\n",
        "     <p>In a real web application, this page would use your microphone to record your vocals over the beat.</p>\n",
        "     <p>For this demonstration, you can create a dummy recording file to proceed with the combining step.</p>\n",
        "     <p><a href=\"{{ url_for('create_dummy_recording') }}\">Create Dummy Recording File</a></p>\n",
        "     <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "     ''')\n",
        "\n",
        "@app.route('/create_dummy_recording')\n",
        "def create_dummy_recording():\n",
        "    global audio_duration_s\n",
        "    dummy_recording_path = 'user_recordings/user_performance.wav'\n",
        "    # Create a dummy recording with the same duration as the processed audio\n",
        "    record_audio_dummy(dummy_recording_path, audio_duration_s if audio_duration_s > 0 else 10) # Default to 10 secs if duration is 0\n",
        "    return redirect(url_for('index'))\n",
        "\n",
        "\n",
        "@app.route('/combine')\n",
        "def combine():\n",
        "    global processed_audio_path\n",
        "    user_recording_path = 'user_recordings/user_performance.wav' # Assume this is the default recording file\n",
        "\n",
        "    if not processed_audio_path or not os.path.exists(processed_audio_path):\n",
        "        return \"Error: Processed beat audio not available.\", 400\n",
        "    if not os.path.exists(user_recording_path):\n",
        "        return f\"Error: User recording not found at {user_recording_path}. Please ensure a recording has been made (or a dummy file exists).\", 400\n",
        "\n",
        "    final_mix_path = combine_audio(processed_audio_path, user_recording_path)\n",
        "\n",
        "    if final_mix_path.startswith(\"Error\"):\n",
        "        return final_mix_path, 500\n",
        "    else:\n",
        "        return render_template_string('''\n",
        "        <!doctype html>\n",
        "        <title>Combine Audio</title>\n",
        "        <h1>Audio Combined!</h1>\n",
        "        <p>Final mix saved to: {{ final_mix_path }}</p>\n",
        "        <p><a href=\"{{ url_for('download_mix') }}\">Download Final Mix</a></p>\n",
        "        <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "        ''', final_mix_path=final_mix_path)\n",
        "\n",
        "@app.route('/download_mix')\n",
        "def download_mix():\n",
        "    final_mix_path = 'final_mixes/final_performance_mix.wav'\n",
        "    if os.path.exists(final_mix_path):\n",
        "        return send_file(final_mix_path, as_attachment=True)\n",
        "    else:\n",
        "        return \"Error: Final mix file not found.\", 404\n",
        "\n",
        "\n",
        "# To run the Flask app (for demonstration purposes)\n",
        "# Note: In a Colab environment, you might need to use ngrok or a similar service\n",
        "# to expose your local Flask server to the internet for testing in a browser.\n",
        "# For simple testing within Colab, you can use the built-in preview.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This will run the Flask development server\n",
        "    # debug=True allows for automatic reloading and helpful error pages\n",
        "    # Set host='0.0.0.0' to make the server accessible externally if needed (e.e., for ngrok)\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bca83b71a3f047869f063b06e70a4c9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db086c68716847e4a99437fe10b7534d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1abfd5648e14a85905818272e35b9a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48124b12bee44b8cb02c88a356129db2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40f225881b524cc99c80e79f3b97329d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30dad2eef7e24187a984061b2866c749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2de6da14316841c594a9875d9ac18844",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded distilgpt2 model for text generation.\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ag6GI3_SIQd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "771d78d9"
      },
      "source": [
        "# Generate lyrics with a different genre and theme using the updated create_lyric_prompt function\n",
        "\n",
        "user_genre_example_2 = \"Hip Hop\"\n",
        "user_theme_example_2 = \"overcoming challenges\"\n",
        "explicit_toggle_example_2 = True\n",
        "\n",
        "if audio_analysis_results is not None and generator is not None:\n",
        "    # Create the prompt with the new genre and theme\n",
        "    lyric_prompt_example_2 = create_lyric_prompt(audio_analysis_results, user_genre_example_2, user_theme_example_2, explicit_toggle_example_2)\n",
        "    print(f\"\\nGenerated Prompt (Hip Hop Example):\\n{lyric_prompt_example_2}\")\n",
        "\n",
        "    try:\n",
        "        # Generate lyrics using the language model\n",
        "        generated_lyrics_example_2 = generator(\n",
        "            lyric_prompt_example_2,\n",
        "            max_length=300,  # Adjust max_length as needed\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            truncation=True\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        # Attempt to remove the prompt from the generated text\n",
        "        if generated_lyrics_example_2.startswith(lyric_prompt_example_2):\n",
        "            generated_lyrics_example_2 = generated_lyrics_example_2[len(lyric_prompt_example_2):].strip()\n",
        "\n",
        "\n",
        "        print(\"\\nGenerated Lyrics (Hip Hop Example):\")\n",
        "        print(generated_lyrics_example_2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Hip Hop lyric generation: {e}\")\n",
        "else:\n",
        "    print(\"Audio analysis results or language model not available, cannot generate Hip Hop lyrics.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef982394"
      },
      "source": [
        "# Refine the lyric prompt and generate lyrics using the model\n",
        "\n",
        "# Using the example user inputs from the previous step\n",
        "user_genre_example = \"Blues\"\n",
        "user_theme_example = \"hard times\"\n",
        "explicit_toggle_example = False\n",
        "\n",
        "if audio_analysis_results is not None and generator is not None:\n",
        "    # Create the refined prompt\n",
        "    refined_lyric_prompt = create_lyric_prompt(audio_analysis_results, user_genre_example, user_theme_example, explicit_toggle_example)\n",
        "    print(f\"\\nUsing Refined Prompt:\\n{refined_lyric_prompt}\")\n",
        "\n",
        "    try:\n",
        "        # Generate lyrics using the language model with the refined prompt\n",
        "        # Adjust max_length and other parameters as needed for desired lyric length and style\n",
        "        generated_lyrics_refined = generator(\n",
        "            refined_lyric_prompt,\n",
        "            max_length=500,  # Increased max_length\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9, # Increased temperature for more creativity\n",
        "            top_k=50,       # Added top_k sampling\n",
        "            top_p=0.95,     # Added top_p (nucleus) sampling\n",
        "            truncation=True\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        # Attempt to remove the prompt from the generated text\n",
        "        if generated_lyrics_refined.startswith(refined_lyric_prompt):\n",
        "            generated_lyrics_refined = generated_lyrics_refined[len(refined_lyric_prompt):].strip()\n",
        "\n",
        "        print(\"\\nGenerated Lyrics (Refined):\")\n",
        "        print(generated_lyrics_refined)\n",
        "\n",
        "        # You can store this in a variable for later use, e.g., for the playback and sync step\n",
        "        final_generated_lyrics = generated_lyrics_refined\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during refined lyric generation: {e}\")\n",
        "        final_generated_lyrics = None\n",
        "else:\n",
        "    print(\"Audio analysis results or language model not available, cannot generate refined lyrics.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0b8daee"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `yt-dlp` library was not installed. I need to install `yt-dlp` and its dependencies, including `ffmpeg` which is required by `pydub` for audio format conversion and by `yt-dlp` for post-processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEX-beM3YRo3"
      },
      "source": [
        "!pip install yt-dlp pydub Flask\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6719de2b"
      },
      "source": [
        "**Reasoning**:\n",
        "The necessary libraries and ffmpeg have been installed. Now I can re-run the code to define the `process_audio_input` function and the basic Flask app setup, which addresses steps 3, 4, and 5 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82bda107"
      },
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from flask import Flask, request, render_template_string, redirect, url_for\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "# Define allowed file types for upload\n",
        "ALLOWED_EXTENSIONS = {'mp3', 'wav'}\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def process_audio_input(input_source):\n",
        "    \"\"\"\n",
        "    Processes audio input from either a file upload or a URL.\n",
        "\n",
        "    Args:\n",
        "        input_source: Either a file storage object (from Flask request.files) or a string URL.\n",
        "\n",
        "    Returns:\n",
        "        The path to the processed WAV file, or None if processing failed.\n",
        "    \"\"\"\n",
        "    output_dir = 'processed_audio'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    if hasattr(input_source, 'filename'):  # Handle file upload\n",
        "        if input_source and allowed_file(input_source.filename):\n",
        "            filename = secure_filename(input_source.filename)\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            input_source.save(filepath)\n",
        "            try:\n",
        "                audio = AudioSegment.from_file(filepath)\n",
        "                wav_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.wav')\n",
        "                audio.export(wav_path, format='wav')\n",
        "                os.remove(filepath) # Clean up the original uploaded file\n",
        "                return wav_path\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing uploaded audio file: {e}\")\n",
        "                os.remove(filepath)\n",
        "                return None\n",
        "        else:\n",
        "            print(\"Invalid file type or no file uploaded.\")\n",
        "            return None\n",
        "    elif isinstance(input_source, str): # Handle URL\n",
        "        url = input_source\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'wav',\n",
        "                }],\n",
        "                'outtmpl': os.path.join(output_dir, '%(title)s.%(ext)s'),\n",
        "                'extract_flat': True,\n",
        "                'noplaylist': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(url, download=False)\n",
        "                if 'entries' in info_dict: # Handle playlists, although we set noplaylist=True, some URLs might be interpreted as playlists\n",
        "                    info_dict = info_dict['entries'][0] # Take the first video\n",
        "                title = info_dict.get('title', 'downloaded_audio')\n",
        "                output_filename = os.path.join(output_dir, f\"{title}.wav\")\n",
        "                ydl.download([url])\n",
        "                return output_filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio from URL: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Invalid input source.\")\n",
        "        return None\n",
        "\n",
        "# Example Flask app setup for demonstration (can be adapted for the final application)\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads' # Not strictly needed with the current logic, but good practice\n",
        "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_or_download():\n",
        "    processed_file = None\n",
        "    if request.method == 'POST':\n",
        "        if 'audio_file' in request.files:\n",
        "            audio_file = request.files['audio_file']\n",
        "            processed_file = process_audio_input(audio_file)\n",
        "        elif 'audio_url' in request.form:\n",
        "            audio_url = request.form['audio_url']\n",
        "            processed_file = process_audio_input(audio_url)\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Upload or Download Audio</title>\n",
        "    <h1>Upload an audio file or provide a URL</h1>\n",
        "    <form method=post enctype=multipart/form-data>\n",
        "      <p><input type=file name=audio_file>\n",
        "         <input type=submit value=Upload>\n",
        "    </form>\n",
        "    <form method=post>\n",
        "      <p><input type=text name=audio_url placeholder=\"Enter URL\">\n",
        "         <input type=submit value=Download>\n",
        "    </form>\n",
        "    {% if processed_file %}\n",
        "    <h2>Processed Audio:</h2>\n",
        "    <p>File saved at: {{ processed_file }}</p>\n",
        "    {% endif %}\n",
        "    ''', processed_file=processed_file)\n",
        "\n",
        "# To run this example Flask app, you would typically use:\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4da36432"
      },
      "source": [
        "## Audio analysis\n",
        "\n",
        "### Subtask:\n",
        "Implement audio analysis to detect BPM, tempo, and mood. We can use libraries like Librosa for this purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbaacd34"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for audio analysis and load the processed audio file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "227fec96"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Assuming the previous step saved the processed WAV file to 'processed_audio/downloaded_audio.wav' or similar\n",
        "# We need a placeholder filename for demonstration purposes.\n",
        "# In a real application, you would get the actual filename from the previous step's output.\n",
        "processed_audio_path = 'processed_audio/downloaded_audio.wav' # Replace with actual path\n",
        "\n",
        "# Create a dummy file if it doesn't exist for demonstration\n",
        "if not os.path.exists('processed_audio'):\n",
        "    os.makedirs('processed_audio')\n",
        "if not os.path.exists(processed_audio_path):\n",
        "    # Create a silent WAV file for demonstration if the real one doesn't exist\n",
        "    import soundfile as sf\n",
        "    samplerate = 22050\n",
        "    duration = 10\n",
        "    data = np.zeros(duration * samplerate)\n",
        "    sf.write(processed_audio_path, data, samplerate)\n",
        "    print(f\"Created a dummy WAV file at: {processed_audio_path}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    y, sr = librosa.load(processed_audio_path)\n",
        "    print(f\"Successfully loaded audio file: {processed_audio_path}\")\n",
        "    print(f\"Audio time series shape: {y.shape}\")\n",
        "    print(f\"Sampling rate: {sr}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file: {e}\")\n",
        "    y, sr = None, None # Set to None if loading fails\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d475f494"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the BPM and tempo using librosa's beat tracking function and explore potential mood detection methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdb7f1ee"
      },
      "source": [
        "# Calculate BPM and tempo\n",
        "if y is not None and sr is not None:\n",
        "    try:\n",
        "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "        print(f\"Estimated BPM: {tempo:.2f}\")\n",
        "        # beat_frames contains the frame indices of the detected beats\n",
        "        # To get the time of the beats: librosa.frames_to_time(beat_frames, sr=sr)\n",
        "\n",
        "        # Mood detection - Exploring methods\n",
        "        # Librosa itself doesn't have a direct 'mood' function.\n",
        "        # Mood is a complex concept often derived from a combination of features.\n",
        "        # Potential features to analyze for mood:\n",
        "        # 1. Spectral Centroid: Indicates the 'brightness' of the sound. Higher values can suggest happier/brighter moods.\n",
        "        # 2. Spectral Rolloff: Indicates the shape of the spectrum. Can relate to the 'darkness' or 'brightness'.\n",
        "        # 3. Zero-Crossing Rate: How often the signal crosses the zero axis. Higher values can indicate more percussive or energetic sounds.\n",
        "        # 4. Mel-Frequency Cepstral Coefficients (MFCCs): Capture the timbre of the sound. Can be used as features for a mood classification model.\n",
        "        # 5. Chroma Features: Represent the spectral energy across different pitch classes. Can be related to harmony and tonality, which influence mood.\n",
        "        # 6. Tempo and Rhythm features (already calculated): Fast tempo often relates to energetic/happy moods, slow tempo to calm/sad moods.\n",
        "        # 7. Dynamic Range/Loudness: Can relate to intensity and energy.\n",
        "\n",
        "        # For a simple estimation without a pre-trained model, we can combine a few features.\n",
        "        # A very basic approach could be to look at tempo and spectral features.\n",
        "        # Let's calculate spectral centroid and zero-crossing rate as examples.\n",
        "\n",
        "        # Calculate spectral centroid\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "        # Calculate zero-crossing rate\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "\n",
        "        # Simple heuristic for mood (highly simplified for demonstration)\n",
        "        # This is NOT a robust mood detection method but illustrates using features.\n",
        "        # A real-world application would use a trained machine learning model.\n",
        "        mean_centroid = np.mean(spectral_centroids)\n",
        "        mean_zcr = np.mean(zcr)\n",
        "\n",
        "        estimated_mood = \"Neutral\" # Default mood\n",
        "        if tempo > 120 and mean_centroid > 2000: # Higher tempo and brighter sound\n",
        "            estimated_mood = \"Energetic/Happy\"\n",
        "        elif tempo < 80 and mean_centroid < 1500: # Lower tempo and darker sound\n",
        "             estimated_mood = \"Calm/Sad\"\n",
        "        elif tempo > 140 and mean_zcr > 0.1: # Very high tempo and high ZCR\n",
        "             estimated_mood = \"Fast/Intense\"\n",
        "\n",
        "        print(f\"Estimated Mood (Simplified Heuristic): {estimated_mood}\")\n",
        "\n",
        "        # Store the results\n",
        "        audio_analysis_results = {\n",
        "            'bpm': tempo,\n",
        "            'tempo': tempo, # BPM and tempo are often used interchangeably in this context\n",
        "            'estimated_mood': estimated_mood\n",
        "        }\n",
        "        print(\"Audio analysis results stored.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during audio analysis: {e}\")\n",
        "        audio_analysis_results = None # Set to None if analysis fails\n",
        "else:\n",
        "    print(\"Audio data not loaded, skipping analysis.\")\n",
        "    audio_analysis_results = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "874060f9"
      },
      "source": [
        "## Ai lyrics generation\n",
        "\n",
        "### Subtask:\n",
        "Set up an AI model to generate lyrics based on the analyzed audio features (BPM, tempo, mood) and user-specified parameters (genre, theme, explicit toggle). This will involve choosing and integrating a suitable language model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8a9e66d"
      },
      "source": [
        "**Reasoning**:\n",
        "Choose a suitable language model and integrate it with the audio analysis results and user inputs to generate lyrics. I will use the `transformers` library to interact with a pre-trained language model suitable for text generation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00796ab8"
      },
      "source": [
        "from transformers import pipelinem\n",
        "\n",
        "# Choose a suitable language modelm\n",
        "# 'gpt2' is a good starting point for text generation due to its availability and capability.\n",
        "# For more creative or longer lyrics, larger models might be considered, but require more resources.\n",
        "# We'll use a text generation pipeline for ease of use.\n",
        "try:\n",
        "    generator = pipeline('text-generation', model='gpt2')\n",
        "    print(\"Successfully loaded GPT-2 model for text generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading language model: {e}\")\n",
        "    generator = None\n",
        "\n",
        "# Design the prompt structure\n",
        "# The prompt should incorporate the audio features and user preferences.\n",
        "# We'll create a function to generate the prompt string.\n",
        "def create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"\n",
        "    Creates a prompt string for the language model based on audio features and user inputs.\n",
        "\n",
        "    Args:\n",
        "        audio_features: Dictionary containing 'bpm', 'tempo', 'estimated_mood'.\n",
        "        user_genre: User-specified music genre (e.g., \"Hip Hop\", \"Pop\", \"Rock\").\n",
        "        user_theme: User-specified theme for the lyrics (e.g., \"love\", \"party\", \"struggle\").\n",
        "        explicit_toggle: Boolean indicating whether explicit lyrics are allowed.\n",
        "\n",
        "    Returns:\n",
        "        A formatted prompt string.\n",
        "    \"\"\"\n",
        "    prompt = f\"Generate lyrics for a song. \"\n",
        "\n",
        "    if user_genre:\n",
        "        prompt += f\"The genre is {user_genre}. \"\n",
        "    if user_theme:\n",
        "        prompt += f\"The theme is about {user_theme}. \"\n",
        "\n",
        "    # Incorporate audio features (BPM and Mood are most relevant for lyrical flow and content)\n",
        "    if audio_features:\n",
        "        if audio_features.get('bpm') is not None and audio_features['bpm'] > 0:\n",
        "             # Adjusting prompt based on BPM for rhythm suggestion\n",
        "             if audio_features['bpm'] < 80:\n",
        "                 prompt += \"The beat is slow, the lyrics should have a relaxed flow. \"\n",
        "             elif audio_features['bpm'] < 120:\n",
        "                 prompt += \"The beat has a moderate pace. \"\n",
        "             else:\n",
        "                 prompt += \"The beat is fast and energetic, the lyrics should match the rhythm. \"\n",
        "\n",
        "        if audio_features.get('estimated_mood'):\n",
        "            prompt += f\"The mood of the music is {audio_features['estimated_mood']}. \"\n",
        "\n",
        "    # Add explicit toggle consideration (simple instruction for the model)\n",
        "    if not explicit_toggle:\n",
        "        prompt += \"Avoid explicit language. \"\n",
        "\n",
        "    prompt += \"Here are the lyrics:\" # Indicate where the generated lyrics should start\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Example usage of the prompt creation function\n",
        "# Assuming some placeholder user inputs for demonstration\n",
        "user_genre = \"Hip Hop\"\n",
        "user_theme = \"overcoming challenges\"\n",
        "explicit_toggle = True # Allow explicit lyrics\n",
        "\n",
        "if audio_analysis_results is not None:\n",
        "    lyric_prompt = create_lyric_prompt(audio_analysis_results, user_genre, user_theme, explicit_toggle)\n",
        "    print(f\"\\nGenerated Prompt:\\n{lyric_prompt}\")\n",
        "\n",
        "    # Generate lyrics using the model\n",
        "    if generator is not None:\n",
        "        try:\n",
        "            # Generate a sequence of tokens. max_length controls the length of the generated text.\n",
        "            # num_return_sequences can generate multiple options.\n",
        "            # temperature can control randomness (higher temperature = more creative/random).\n",
        "            # top_k and top_p can control the sampling strategy.\n",
        "            # We'll use a basic generation for now.\n",
        "            generated_lyrics = generator(lyric_prompt, max_length=150, num_return_sequences=1, temperature=0.7)[0]['generated_text']\n",
        "\n",
        "            # The model might include the prompt in the output, so we can try to remove it.\n",
        "            if generated_lyrics.startswith(lyric_prompt):\n",
        "                generated_lyrics = generated_lyrics[len(lyric_prompt):].strip()\n",
        "\n",
        "            print(\"\\nGenerated Lyrics:\")\n",
        "            print(generated_lyrics)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during lyric generation: {e}\")\n",
        "    else:\n",
        "        print(\"Language model not loaded, cannot generate lyrics.\")\n",
        "else:\n",
        "    print(\"Audio analysis results not available, cannot create lyric prompt.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14a1f74a"
      },
      "source": [
        "## Lyric Editing\n",
        "\n",
        "### Subtask:\n",
        "Implement basic editing features for the generated lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aad9074f"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement basic editing features for the generated lyrics using `ipywidgets` to create an interactive text area within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5acc6096"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Assume 'final_generated_lyrics' is available from the previous step\n",
        "# If not, use a placeholder for demonstration.\n",
        "if 'final_generated_lyrics' not in locals() or not final_generated_lyrics:\n",
        "    final_generated_lyrics = \"\"\"\n",
        "    (Verse 1)\n",
        "    This is a placeholder lyric,\n",
        "    Ready for you to edit it quick.\n",
        "    (Chorus)\n",
        "    Change these lines, make them shine,\n",
        "    Your creativity, truly divine.\n",
        "    \"\"\"\n",
        "    print(\"Using placeholder lyrics for the editing step.\")\n",
        "\n",
        "# Create a Textarea widget for editing\n",
        "lyrics_textarea = widgets.Textarea(\n",
        "    value=final_generated_lyrics,\n",
        "    description='Edit Lyrics:',\n",
        "    disabled=False,\n",
        "    layout={'width': '80%', 'height': '300px'}\n",
        ")\n",
        "\n",
        "# Create a button to simulate saving the edited lyrics\n",
        "save_button = widgets.Button(\n",
        "    description='Save Lyrics',\n",
        "    disabled=False,\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to save the edited lyrics'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_save_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "        global final_generated_lyrics\n",
        "        final_generated_lyrics = lyrics_textarea.value\n",
        "        print(\"Lyrics saved:\")\n",
        "        print(final_generated_lyrics)\n",
        "        # In a real application, you would save the edited_lyrics to a file or database\n",
        "\n",
        "save_button.on_click(on_save_button_clicked)\n",
        "\n",
        "print(\"Edit the lyrics in the text area below and click 'Save Lyrics'.\")\n",
        "display(lyrics_textarea, save_button, output_area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f8f85d2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps failed because of missing audio libraries (`PortAudio` and `libsndfile`). Install these libraries using `apt-get`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95bb0b93"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libportaudio2 libsndfile1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1e6a448"
      },
      "source": [
        "## Recording and Export\n",
        "\n",
        "### Subtask:\n",
        "Implement audio recording and export functionality to capture user performances and create a final output file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eab5307c"
      },
      "source": [
        "**Reasoning**:\n",
        "Install necessary libraries for audio recording and processing (`sounddevice`, `numpy`, `scipy`, and ensure `ffmpeg` is installed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cce40df9"
      },
      "source": [
        "!pip install sounddevice numpy scipy\n",
        "!apt-get update && apt-get install -y ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b6d91e7"
      },
      "source": [
        "**Reasoning**:\n",
        "Develop code to record audio from the user's microphone. This will use `sounddevice` to capture input for a specified duration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6295953"
      },
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Define recording parameters\n",
        "samplerate = 44100  # Standard audio CD quality\n",
        "duration = 10       # seconds (you can adjust this or make it dynamic)\n",
        "# Ensure the output directory exists\n",
        "output_dir = 'user_recordings'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_filename = os.path.join(output_dir, 'user_performance.wav')\n",
        "\n",
        "print(f\"Preparing to record for {duration} seconds...\")\n",
        "print(\"Speak into your microphone when prompted.\")\n",
        "\n",
        "# Function to handle the recording\n",
        "def record_audio(filename, samplerate, duration):\n",
        "    print(\"Recording...\")\n",
        "    myrecording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')\n",
        "    sd.wait()  # Wait until recording is finished\n",
        "    wav.write(filename, samplerate, myrecording)\n",
        "    print(f\"Recording saved to {filename}\")\n",
        "\n",
        "# Note: In a real application within a web browser, you would use Web Audio API\n",
        "# for microphone access and recording, as direct access via Python in a notebook\n",
        "# might have limitations depending on the environment. This is a basic demonstration.\n",
        "\n",
        "# You would typically trigger this function when the user clicks a 'Record' button.\n",
        "# For demonstration, we'll call it directly.\n",
        "\n",
        "# record_audio(output_filename, samplerate, duration) # Uncomment to run recording\n",
        "# print(\"Recording code is defined. Uncomment the function call to run.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b3fd4cb"
      },
      "source": [
        "**Reasoning**:\n",
        "Develop code to combine the recorded user audio with the original beat audio using `pydub` (which requires `ffmpeg`). This involves loading both audio files, overlaying them, and exporting the combined audio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2046f39b"
      },
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Assuming processed_audio_path and output_filename (user recording) are available\n",
        "# If not, use placeholders for demonstration.\n",
        "if 'processed_audio_path' not in locals() or not os.path.exists(processed_audio_path):\n",
        "     processed_audio_path = 'processed_audio/downloaded_audio.wav'\n",
        "     # Create dummy if it doesn't exist (should be handled by earlier steps)\n",
        "     if not os.path.exists(processed_audio_path):\n",
        "        import soundfile as sf\n",
        "        samplerate = 22050\n",
        "        duration = 10\n",
        "        data = np.zeros(duration * samplerate)\n",
        "        sf.write(processed_audio_path, data, samplerate)\n",
        "        print(f\"Created a dummy processed_audio.wav at: {processed_audio_path}\")\n",
        "\n",
        "if 'output_filename' not in locals() or not os.path.exists(output_filename):\n",
        "     output_filename = 'user_recordings/user_performance.wav'\n",
        "     # Create dummy if it doesn't exist (you would replace this with an actual recording)\n",
        "     if not os.path.exists(output_filename):\n",
        "         import soundfile as sf\n",
        "         samplerate = 44100\n",
        "         duration = 10\n",
        "         data = np.random.rand(duration * samplerate) * 0.1 # Little bit of noise\n",
        "         sf.write(output_filename, data, samplerate)\n",
        "         print(f\"Created a dummy user_performance.wav at: {output_filename}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    # Load the beat and the recorded vocals\n",
        "    beat_audio = AudioSegment.from_wav(processed_audio_path)\n",
        "    vocal_audio = AudioSegment.from_wav(output_filename)\n",
        "\n",
        "    # Ensure both audio segments have the same frame rate (important for overlaying)\n",
        "    # If they don't, resample one to match the other.\n",
        "    if beat_audio.frame_rate != vocal_audio.frame_rate:\n",
        "        print(f\"Warning: Mismatch in frame rates. Resampling vocal audio from {vocal_audio.frame_rate} to {beat_audio.frame_rate}\")\n",
        "        vocal_audio = vocal_audio.set_frame_rate(beat_audio.frame_rate)\n",
        "\n",
        "\n",
        "    # Ensure both audio segments are of similar length for simple overlay\n",
        "    # In a real app, you'd likely trim or loop the beat, or handle different lengths based on performance.\n",
        "    min_duration = min(len(beat_audio), len(vocal_audio))\n",
        "    beat_audio = beat_audio[:min_duration]\n",
        "    vocal_audio = vocal_audio[:min_duration]\n",
        "\n",
        "\n",
        "    # Overlay the vocal track onto the beat track\n",
        "    # You might need to adjust the volume of one track relative to the other for a good mix\n",
        "    # For example: beat_audio.overlay(vocal_audio - 5) # Reduce vocal volume by 5 dB\n",
        "    combined_audio = beat_audio.overlay(vocal_audio)\n",
        "\n",
        "    # Export the combined audio\n",
        "    export_dir = 'final_mixes'\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "    final_output_path = os.path.join(export_dir, 'final_performance_mix.wav')\n",
        "    combined_audio.export(final_output_path, format=\"wav\")\n",
        "\n",
        "    print(f\"Combined audio exported to: {final_output_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error combining audio files: {e}\")\n",
        "    print(\"Please ensure both processed_audio.wav and user_performance.wav exist and are valid audio files.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d760860"
      },
      "source": [
        "**Reasoning**:\n",
        "(Optional, but part of a full export feature) Develop code to combine the mixed audio with the visualizer (and potentially synchronized lyrics as a subtitle track or burned-in text) into a single video file using `ffmpeg`. This is a more complex step and might require exploring `ffmpeg` command-line arguments or Python wrappers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8878e6"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# This is a more advanced step requiring careful use of ffmpeg.\n",
        "# Combining audio, visualizer animation (if dynamic), and lyrics into video\n",
        "# would typically involve:\n",
        "# 1. Generating the dynamic visualizer frames as images.\n",
        "# 2. Generating a subtitle file (like .srt) for the synchronized lyrics.\n",
        "# 3. Using ffmpeg to combine the beat+vocal audio, visualizer images, and subtitles into an MP4 or other video format.\n",
        "\n",
        "# Example of a basic ffmpeg command to combine audio and a static image into a video:\n",
        "# subprocess.run(['ffmpeg', '-loop', '1', '-i', 'static_visualizer.png', '-i', 'final_mixes/final_performance_mix.wav', '-c:v', 'libx264', '-tune', 'stillimage', '-c:a', 'aac', '-b:a', '192k', '-pix_fmt', 'yuv420p', '-shortest', 'final_output.mp4'])\n",
        "\n",
        "# A dynamic visualizer and synchronized lyrics would significantly increase complexity.\n",
        "# For now, we'll focus on the audio mix. Full video export can be a later enhancement.\n",
        "\n",
        "print(\"Video export functionality (combining audio, visualizer, lyrics) is complex and would require generating video frames and potentially subtitle files.\")\n",
        "print(\"The code for audio mixing is provided in the previous cell.\")\n",
        "print(\"Full video export can be explored as a further enhancement.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ed04724"
      },
      "source": [
        "## Playback and lyric sync\n",
        "\n",
        "### Subtask:\n",
        "Develop a system to play the uploaded beat and display the generated lyrics in a karaoke-style synchronized manner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c0acf2f"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries for audio playback and lyric synchronization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d0f9524"
      },
      "source": [
        "import time\n",
        "import threading\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "# Assuming the processed audio path from the previous step\n",
        "processed_audio_path = 'processed_audio/downloaded_audio.wav'\n",
        "\n",
        "# Assuming 'final_generated_lyrics' is available from the previous subtask as a string\n",
        "# Use the refined lyrics if available, otherwise use the dummy\n",
        "if 'final_generated_lyrics' in locals() and final_generated_lyrics:\n",
        "    generated_lyrics_to_sync = final_generated_lyrics\n",
        "    print(\"Using refined generated_lyrics for synchronization.\")\n",
        "elif 'generated_lyrics' in locals() and generated_lyrics:\n",
        "     generated_lyrics_to_sync = generated_lyrics\n",
        "     print(\"Using initial generated_lyrics for synchronization.\")\n",
        "else:\n",
        "    generated_lyrics_to_sync = \"\"\"\n",
        "    (Verse 1)\n",
        "    Yo, the beat is slow, feeling the flow,\n",
        "    Sun going down, putting on a show.\n",
        "    Got that calm vibe, nothing to hide,\n",
        "    Just chilling here, with the worldwide tide.\n",
        "\n",
        "    (Chorus)\n",
        "    Calm and sad, but not really bad,\n",
        "    Just reflecting on the times we had.\n",
        "    The tempo's low, letting emotions show,\n",
        "    In this mellow groove, watch the feelings grow.\n",
        "\n",
        "    (Verse 2)\n",
        "    Streetlights are dim, thoughts within,\n",
        "    Where do we end, and where do we begin?\n",
        "    Spectral centroid low, a gentle glow,\n",
        "    Through the quiet night, watch the moments go.\n",
        "\n",
        "    (Bridge)\n",
        "    Zero crossings are few, feeling blue,\n",
        "    But in a peaceful way, me and you.\n",
        "    No need to rush, in this evening hush,\n",
        "    Just the sound of the beat, a gentle brush.\n",
        "\n",
        "    (Chorus)\n",
        "    Calm and sad, but not really bad,\n",
        "    Just reflecting on the times we had.\n",
        "    The tempo's low, letting emotions show,\n",
        "    In this mellow groove, watch the feelings grow.\n",
        "\n",
        "    (Outro)\n",
        "    Yeah, calm and sad, fading out slow,\n",
        "    Letting the music take control.\n",
        "    Peaceful end, until we meet again,\n",
        "    In this calm moment, where the feelings blend.\n",
        "    \"\"\"\n",
        "    print(\"Using dummy generated_lyrics for demonstration.\")\n",
        "\n",
        "\n",
        "# Load the audio file\n",
        "try:\n",
        "    audio_segment = AudioSegment.from_wav(processed_audio_path)\n",
        "    audio_duration_ms = len(audio_segment)\n",
        "    print(f\"Audio file loaded successfully. Duration: {audio_duration_ms} ms\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file: {e}\")\n",
        "    audio_segment = None\n",
        "    audio_duration_ms = 0\n",
        "\n",
        "# Simple lyric synchronization strategy\n",
        "# Split lyrics into lines and distribute them evenly over the audio duration.\n",
        "lyrics_lines = generated_lyrics_to_sync.strip().split('\\n')\n",
        "num_lines = len(lyrics_lines)\n",
        "line_duration_ms = audio_duration_ms / num_lines if num_lines > 0 else 0\n",
        "print(f\"Splitting lyrics into {num_lines} lines.\")\n",
        "print(f\"Estimated duration per line: {line_duration_ms:.2f} ms\")\n",
        "\n",
        "\n",
        "def play_audio(segment):\n",
        "    \"\"\"Plays the given pydub AudioSegment.\"\"\"\n",
        "    if segment:\n",
        "        print(\"Starting audio playback...\")\n",
        "        play(segment)\n",
        "        print(\"Audio playback finished.\")\n",
        "    else:\n",
        "        print(\"No audio segment to play.\")\n",
        "\n",
        "def display_lyrics(lines, line_duration):\n",
        "    \"\"\"Displays lyrics line by line with simulated timing.\"\"\"\n",
        "    print(\"Starting lyric display...\")\n",
        "    for i, line in enumerate(lines):\n",
        "        print(line)\n",
        "        if i < len(lines) - 1:\n",
        "            # Sleep for the estimated duration of the line\n",
        "            time.sleep(line_duration / 1000.0) # time.sleep expects seconds\n",
        "    print(\"Lyric display finished.\")\n",
        "\n",
        "# Ensure playback and lyric display start simultaneously using threads\n",
        "if audio_segment:\n",
        "    # Create threads for audio playback and lyric display\n",
        "    audio_thread = threading.Thread(target=play_audio, args=(audio_segment,))\n",
        "    lyrics_thread = threading.Thread(target=display_lyrics, args=(lyrics_lines, line_duration_ms))\n",
        "\n",
        "    # Start both threads\n",
        "    audio_thread.start()\n",
        "    lyrics_thread.start()\n",
        "\n",
        "    # Wait for both threads to complete\n",
        "    audio_thread.join()\n",
        "    lyrics_thread.join()\n",
        "\n",
        "    print(\"Playback and lyric display completed.\")\n",
        "else:\n",
        "    print(\"Cannot start playback and lyric display due to audio loading error.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46f4023f"
      },
      "source": [
        "## Simple visualizer\n",
        "\n",
        "### Subtask:\n",
        "Create a basic soundwave visualizer that reacts to the audio playback.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2e931c2"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for creating the soundwave visualizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0c81cf6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9a37c35"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the audio file, calculate RMS energy, create a time axis, and plot the soundwave visualizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9abc9866"
      },
      "source": [
        "# Assume processed_audio_path and sr are available from previous steps\n",
        "# If not, define them for demonstration purposes.\n",
        "if 'processed_audio_path' not in locals():\n",
        "    processed_audio_path = 'processed_audio/downloaded_audio.wav' # Placeholder\n",
        "\n",
        "# Load the audio file\n",
        "try:\n",
        "    y, sr = librosa.load(processed_audio_path)\n",
        "    print(f\"Successfully loaded audio file from {processed_audio_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file: {e}\")\n",
        "    y, sr = None, None\n",
        "\n",
        "if y is not None and sr is not None:\n",
        "    # Calculate RMS energy\n",
        "    rms = librosa.feature.rms(y=y)[0]\n",
        "\n",
        "    # Create a time axis for the RMS values\n",
        "    times = librosa.times_like(rms, sr=sr)\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(times, rms)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"RMS Energy\")\n",
        "    plt.title(\"Soundwave Visualizer\")\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Audio data not available, cannot generate soundwave visualizer.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "316086aa"
      },
      "source": [
        "## Genre expansion\n",
        "\n",
        "### Subtask:\n",
        "Integrate additional genres into the AI lyric generation process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8934603b"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the `create_lyric_prompt` function to include genre-specific instructions and keywords. This involves modifying the existing function to handle a wider variety of genres and incorporate elements that influence lyrical style, structure, and themes based on the selected genre.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "264ef7e4"
      },
      "source": [
        "def create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"\n",
        "    Creates a prompt string for the language model based on audio features and user inputs,\n",
        "    with enhanced genre-specific guidance.\n",
        "\n",
        "    Args:\n",
        "        audio_features: Dictionary containing 'bpm', 'tempo', 'estimated_mood'.\n",
        "        user_genre: User-specified music genre (e.g., \"Hip Hop\", \"Pop\", \"Rock\", \"Blues\", \"Country\", \"Electronic\").\n",
        "        user_theme: User-specified theme for the lyrics (e.g., \"love\", \"party\", \"struggle\", \"nature\", \"heartbreak\").\n",
        "        explicit_toggle: Boolean indicating whether explicit lyrics are allowed.\n",
        "\n",
        "    Returns:\n",
        "        A formatted prompt string.\n",
        "    \"\"\"\n",
        "    prompt = f\"Generate lyrics for a song. \"\n",
        "\n",
        "    # Genre-specific instructions and keywords\n",
        "    genre_instructions = {\n",
        "        \"Hip Hop\": \"Focus on rhythm, rhyme schemes (like AABB, ABAB), wordplay, and storytelling. Use urban vocabulary. Include ad-libs.\",\n",
        "        \"Pop\": \"Write catchy melodies and simple, relatable themes. Use a verse-chorus structure. Keep language accessible.\",\n",
        "        \"Rock\": \"Incorporate powerful imagery, emotional themes, and potentially a bridge section. Can be introspective or rebellious.\",\n",
        "        \"Blues\": \"Express feelings of sadness, hardship, or sometimes resilience. Use a typical AAB lyrical structure within verses. Include themes of struggle, love, or loss.\",\n",
        "        \"Country\": \"Tell a story, often set in rural or small-town environments. Themes of love, loss, hard work, and everyday life. Use straightforward language and relatable scenarios.\",\n",
        "        \"Electronic\": \"Lyrics can be repetitive or sparse, focusing on mood and atmosphere. Themes might be abstract, futuristic, or focused on the party/dance experience.\",\n",
        "        \"R&B\": \"Focus on smooth melodies and emotional expression, often about love, relationships, or desire. Use vocal runs and ad-libs.\",\n",
        "        \"Reggae\": \"Incorporate themes of peace, love, social justice, and spirituality. Use a relaxed rhythm and potentially Jamaican Patois influences.\",\n",
        "        \"Jazz\": \"Lyrics can be improvisational or tell complex stories. Focus on mood and atmosphere, often with themes of love, city life, or introspection.\",\n",
        "        \"Folk\": \"Tell a story, often with simple melodies and acoustic instrumentation in mind. Themes of nature, history, social issues, or personal journeys.\",\n",
        "    }\n",
        "\n",
        "    if user_genre and user_genre in genre_instructions:\n",
        "        prompt += f\"The genre is {user_genre}. {genre_instructions[user_genre]} \"\n",
        "    elif user_genre:\n",
        "        # Fallback for unknown genres\n",
        "        prompt += f\"The genre is {user_genre}. Write lyrics appropriate for this genre. \"\n",
        "\n",
        "    if user_theme:\n",
        "        prompt += f\"The theme is about {user_theme}. \"\n",
        "\n",
        "    # Incorporate audio features (BPM and Mood are most relevant for lyrical flow and content)\n",
        "    if audio_features:\n",
        "        if audio_features.get('bpm') is not None and audio_features['bpm'] > 0:\n",
        "             # Adjusting prompt based on BPM for rhythm suggestion\n",
        "             if audio_features['bpm'] < 80:\n",
        "                 prompt += \"The beat is slow, the lyrics should have a relaxed flow and longer phrases. \"\n",
        "             elif audio_features['bpm'] < 120:\n",
        "                 prompt += \"The beat has a moderate pace, the lyrics can have a balanced flow. \"\n",
        "             else:\n",
        "                 prompt += \"The beat is fast and energetic, the lyrics should match the rhythm with shorter, punchier lines. \"\n",
        "\n",
        "        if audio_features.get('estimated_mood'):\n",
        "            prompt += f\"The mood of the music is {audio_features['estimated_mood']}. The lyrics should reflect this mood. \"\n",
        "\n",
        "    # Add explicit toggle consideration (simple instruction for the model)\n",
        "    if not explicit_toggle:\n",
        "        prompt += \"Avoid explicit language and sensitive topics. \"\n",
        "    else:\n",
        "        prompt += \"Explicit language is allowed. \" # Explicitly state if allowed\n",
        "\n",
        "    prompt += \"Write the lyrics now:\" # Indicate where the generated lyrics should start\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Example usage with a different genre and theme\n",
        "user_genre_example = \"Blues\"\n",
        "user_theme_example = \"hard times\"\n",
        "explicit_toggle_example = False\n",
        "\n",
        "if audio_analysis_results is not None:\n",
        "    lyric_prompt_example = create_lyric_prompt(audio_analysis_results, user_genre_example, user_theme_example, explicit_toggle_example)\n",
        "    print(f\"\\nGenerated Prompt (Example):\\n{lyric_prompt_example}\")\n",
        "\n",
        "    # You would then use the generator with this prompt:\n",
        "    # if generator is not None:\n",
        "    #     generated_lyrics_example = generator(lyric_prompt_example, max_length=150, num_return_sequences=1, temperature=0.7)[0]['generated_text']\n",
        "    #     print(\"\\nGenerated Lyrics (Example):\")\n",
        "    #     print(generated_lyrics_example)\n",
        "else:\n",
        "    print(\"Audio analysis results not available, cannot create example lyric prompt.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e8d3e6"
      },
      "source": [
        "## Visualizer Enhancement\n",
        "\n",
        "### Subtask: Enhance the soundwave visualizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afd00a7c"
      },
      "source": [
        "**Reasoning:**\n",
        "Generate a basic soundwave visualizer as a starting point for enhancement. This code loads the audio, calculates RMS energy, and plots the soundwave."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3db5e869"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# Assume processed_audio_path and sr are available from previous steps\n",
        "# If not, define them for demonstration purposes.\n",
        "if 'processed_audio_path' not in locals() or not os.path.exists(processed_audio_path):\n",
        "    processed_audio_path = 'processed_audio/downloaded_audio.wav' # Placeholder\n",
        "    # Create a dummy file if it doesn't exist for demonstration\n",
        "    if not os.path.exists('processed_audio'):\n",
        "        os.makedirs('processed_audio')\n",
        "    if not os.path.exists(processed_audio_path):\n",
        "        import soundfile as sf\n",
        "        samplerate = 22050\n",
        "        duration = 10\n",
        "        data = np.zeros(duration * samplerate)\n",
        "        sf.write(processed_audio_path, data, samplerate)\n",
        "        print(f\"Created a dummy WAV file at: {processed_audio_path}\")\n",
        "\n",
        "\n",
        "# Load the audio file\n",
        "try:\n",
        "    y, sr = librosa.load(processed_audio_path)\n",
        "    print(f\"Successfully loaded audio file from {processed_audio_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file for visualizer: {e}\")\n",
        "    y, sr = None, None\n",
        "\n",
        "if y is not None and sr is not None:\n",
        "    # Calculate RMS energy over small frames\n",
        "    frame_length = 2048 # You can adjust this\n",
        "    hop_length = 512   # You can adjust this\n",
        "    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    rms_times = librosa.times_like(rms, sr=sr, hop_length=hop_length)\n",
        "\n",
        "    # Set up the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    ax.plot(rms_times, rms, lw=2)\n",
        "    ax.set_ylim(0, rms.max() * 1.1)\n",
        "    ax.set_xlim(0, rms_times.max())\n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(\"RMS Energy\")\n",
        "    ax.set_title(\"Soundwave Visualizer\")\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Audio data not available, cannot generate soundwave visualizer.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIK09iaTIVrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "247a60f5"
      },
      "source": [
        "# Task\n",
        "Create a unified Flask application with a basic frontend structure to handle audio processing, lyric generation, visualization, playback, recording, and export, integrating all the previously developed components into a single web interface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0e29c7e",
        "outputId": "1cd74da9-034b-4ffd-c14c-af968cc2f35f"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libportaudio2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 65.3 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Fetched 65.3 kB in 1s (110 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 126435 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfbabe89",
        "outputId": "794348cb-609e-47a5-bec8-5baeb8925a96"
      },
      "source": [
        "!pip install sounddevice numpy scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
            "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82c63b53"
      },
      "source": [
        "## Unified flask app\n",
        "\n",
        "### Subtask:\n",
        "Consolidate the Flask routes and application logic from the different components into a single Flask application instance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b30fe9b"
      },
      "source": [
        "**Reasoning**:\n",
        "Consolidate the Flask routes and application logic into a single Flask application instance. This involves instantiating the Flask app once, defining all routes using this instance, and ensuring data can be shared between routes. I will combine the relevant code from the previous Flask-related cells into a single cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79f5ab0e"
      },
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from flask import Flask, request, render_template_string, redirect, url_for, send_file\n",
        "from werkzeug.utils import secure_filename\n",
        "import librosa\n",
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "import scipy.io.wavfile as wav\n",
        "import time\n",
        "import threading\n",
        "from transformers import pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import base64 # Import base64 for image encoding\n",
        "from io import BytesIO # Import BytesIO for image buffer\n",
        "\n",
        "# Instantiate a single Flask application\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = 'uploads'\n",
        "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
        "os.makedirs('processed_audio', exist_ok=True)\n",
        "os.makedirs('user_recordings', exist_ok=True)\n",
        "os.makedirs('final_mixes', exist_ok=True)\n",
        "os.makedirs('visualizer_frames', exist_ok=True) # Directory to save visualizer frames\n",
        "\n",
        "\n",
        "# Global variables to share data between routes\n",
        "processed_audio_path = None\n",
        "audio_analysis_results = None\n",
        "final_generated_lyrics = None\n",
        "generator = None # Language model generator instance\n",
        "audio_duration_s = 0 # To store audio duration for visualization\n",
        "\n",
        "\n",
        "# Initialize the language model (can be done once at the start)\n",
        "try:\n",
        "    # Use a smaller model for potentially faster loading in Colab\n",
        "    generator = pipeline('text-generation', model='distilgpt2')\n",
        "    print(\"Successfully loaded distilgpt2 model for text generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading language model: {e}\")\n",
        "    generator = None\n",
        "\n",
        "\n",
        "# Define allowed file types for upload\n",
        "ALLOWED_EXTENSIONS = {'mp3', 'wav'}\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def process_audio_input(input_source):\n",
        "    \"\"\"\n",
        "    Processes audio input from either a file upload or a URL.\n",
        "\n",
        "    Args:\n",
        "        input_source: Either a file storage object (from Flask request.files) or a string URL.\n",
        "\n",
        "    Returns:\n",
        "        The path to the processed WAV file, or None if processing failed.\n",
        "    \"\"\"\n",
        "    output_dir = 'processed_audio'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    if hasattr(input_source, 'filename'):  # Handle file upload\n",
        "        if input_source and allowed_file(input_source.filename):\n",
        "            filename = secure_filename(input_source.filename)\n",
        "            filepath = os.path.join(output_dir, filename)\n",
        "            input_source.save(filepath)\n",
        "            try:\n",
        "                audio = AudioSegment.from_file(filepath)\n",
        "                wav_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.wav')\n",
        "                audio.export(wav_path, format='wav')\n",
        "                os.remove(filepath) # Clean up the original uploaded file\n",
        "                return wav_path\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing uploaded audio file: {e}\")\n",
        "                os.remove(filepath)\n",
        "                return None\n",
        "        else:\n",
        "            print(\"Invalid file type or no file uploaded.\")\n",
        "            return None\n",
        "    elif isinstance(input_source, str): # Handle URL\n",
        "        url = input_source\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'postprocessors': [{\n",
        "                    'key': 'FFmpegExtractAudio',\n",
        "                    'preferredcodec': 'wav',\n",
        "                }],\n",
        "                'outtmpl': os.path.join(output_dir, '%(title)s.%(ext)s'),\n",
        "                'extract_flat': True,\n",
        "                'noplaylist': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info_dict = ydl.extract_info(url, download=False)\n",
        "                if 'entries' in info_dict: # Handle playlists, although we set noplaylist=True, some URLs might be interpreted as playlists\n",
        "                    info_dict = info_dict['entries'][0] # Take the first video\n",
        "                title = info_dict.get('title', 'downloaded_audio')\n",
        "                output_filename = os.path.join(output_dir, f\"{title}.wav\")\n",
        "                ydl.download([url])\n",
        "                return output_filename\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading audio from URL: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Invalid input source.\")\n",
        "        return None\n",
        "\n",
        "def analyze_audio(audio_path):\n",
        "    \"\"\"Analyzes audio to detect BPM, tempo, and mood.\"\"\"\n",
        "    global audio_duration_s\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"Audio file not found for analysis: {audio_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path)\n",
        "        audio_duration_s = librosa.get_duration(y=y, sr=sr)\n",
        "        print(f\"Successfully loaded audio file for analysis: {audio_path}\")\n",
        "        print(f\"Audio duration: {audio_duration_s:.2f} seconds\")\n",
        "\n",
        "\n",
        "        # Calculate BPM and tempo\n",
        "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "        print(f\"Estimated BPM: {tempo:.2f}\")\n",
        "\n",
        "        # Simple heuristic for mood (highly simplified for demonstration)\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "        mean_centroid = np.mean(spectral_centroids)\n",
        "        mean_zcr = np.mean(zcr)\n",
        "\n",
        "        estimated_mood = \"Neutral\"\n",
        "        if tempo > 120 and mean_centroid > 2000:\n",
        "            estimated_mood = \"Energetic/Happy\"\n",
        "        elif tempo < 80 and mean_centroid < 1500:\n",
        "             estimated_mood = \"Calm/Sad\"\n",
        "        elif tempo > 140 and mean_zcr > 0.1:\n",
        "             estimated_mood = \"Fast/Intense\"\n",
        "\n",
        "        print(f\"Estimated Mood (Simplified Heuristic): {estimated_mood}\")\n",
        "\n",
        "        return {\n",
        "            'bpm': tempo,\n",
        "            'tempo': tempo,\n",
        "            'estimated_mood': estimated_mood,\n",
        "            'duration': audio_duration_s,\n",
        "            'y': y, # Store audio time series data for visualizer\n",
        "            'sr': sr  # Store sampling rate for visualizer\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during audio analysis: {e}\")\n",
        "        audio_duration_s = 0\n",
        "        return None\n",
        "\n",
        "def create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"\n",
        "    Creates a prompt string for the language model based on audio features and user inputs,\n",
        "    with enhanced genre-specific guidance.\n",
        "    \"\"\"\n",
        "    prompt = f\"Generate lyrics for a song. \"\n",
        "\n",
        "    genre_instructions = {\n",
        "        \"Hip Hop\": \"Focus on rhythm, rhyme schemes (like AABB, ABAB), wordplay, and storytelling. Use urban vocabulary. Include ad-libs.\",\n",
        "        \"Pop\": \"Write catchy melodies and simple, relatable themes. Use a verse-chorus structure. Keep language accessible.\",\n",
        "        \"Rock\": \"Incorporate powerful imagery, emotional themes, and potentially a bridge section. Can be introspective or rebellious.\",\n",
        "        \"Blues\": \"Express feelings of sadness, hardship, or sometimes resilience. Use a typical AAB lyrical structure within verses. Include themes of struggle, love, or loss.\",\n",
        "        \"Country\": \"Tell a story, often set in rural or small-town environments. Themes of love, loss, hard work, and everyday life. Use straightforward language and relatable scenarios.\",\n",
        "        \"Electronic\": \"Lyrics can be repetitive or sparse, focusing on mood and atmosphere. Themes might be abstract, futuristic, or focused on the party/dance experience.\",\n",
        "        \"R&B\": \"Focus on smooth melodies and emotional expression, often about love, relationships, or desire. Use vocal runs and ad-libs.\",\n",
        "        \"Reggae\": \"Incorporate themes of peace, love, social justice, and spirituality. Use a relaxed rhythm and potentially Jamaican Patois influences.\",\n",
        "        \"Jazz\": \"Lyrics can be improvisational or tell complex stories. Focus on mood and atmosphere, often with themes of love, city life, or introspection.\",\n",
        "        \"Folk\": \"Tell a story, often with simple melodies and acoustic instrumentation in mind. Themes of nature, history, social issues, or personal journeys.\",\n",
        "    }\n",
        "\n",
        "    if user_genre and user_genre in genre_instructions:\n",
        "        prompt += f\"The genre is {user_genre}. {genre_instructions[user_genre]} \"\n",
        "    elif user_genre:\n",
        "        prompt += f\"The genre is {user_genre}. Write lyrics appropriate for this genre. \"\n",
        "\n",
        "    if user_theme:\n",
        "        prompt += f\"The theme is about {user_theme}. \"\n",
        "\n",
        "    if audio_features:\n",
        "        if audio_features.get('bpm') is not None and audio_features['bpm'] > 0:\n",
        "             if audio_features['bpm'] < 80:\n",
        "                 prompt += \"The beat is slow, the lyrics should have a relaxed flow and longer phrases. \"\n",
        "             elif audio_features['bpm'] < 120:\n",
        "                 prompt += \"The beat has a moderate pace, the lyrics can have a balanced flow. \"\n",
        "             else:\n",
        "                 prompt += \"The beat is fast and energetic, the lyrics should match the rhythm with shorter, punchier lines. \"\n",
        "\n",
        "        if audio_features.get('estimated_mood'):\n",
        "            prompt += f\"The mood of the music is {audio_features['estimated_mood']}. The lyrics should reflect this mood. \"\n",
        "\n",
        "    if not explicit_toggle:\n",
        "        prompt += \"Avoid explicit language and sensitive topics. \"\n",
        "    else:\n",
        "        prompt += \"Explicit language is allowed. \"\n",
        "\n",
        "    prompt += \"Write the lyrics now:\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def generate_lyrics(audio_features, user_genre, user_theme, explicit_toggle):\n",
        "    \"\"\"Generates lyrics using the language model.\"\"\"\n",
        "    global generator\n",
        "    if generator is None:\n",
        "        print(\"Language model not loaded.\")\n",
        "        return \"Error: Language model not available.\"\n",
        "\n",
        "    if audio_features is None:\n",
        "        print(\"Audio analysis results not available.\")\n",
        "        return \"Error: Audio analysis results not available.\"\n",
        "\n",
        "    prompt = create_lyric_prompt(audio_features, user_genre, user_theme, explicit_toggle)\n",
        "\n",
        "    try:\n",
        "        generated_text = generator(\n",
        "            prompt,\n",
        "            max_length=500,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.9,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            truncation=True\n",
        "        )[0]['generated_text']\n",
        "\n",
        "        # Attempt to remove the prompt from the generated text\n",
        "        if generated_text.startswith(prompt):\n",
        "            generated_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during lyric generation: {e}\")\n",
        "        return f\"Error generating lyrics: {e}\"\n",
        "\n",
        "# Note: Recording audio directly in Flask server is not typical or recommended.\n",
        "# This function is a placeholder/demonstration. Actual recording would be client-side.\n",
        "def record_audio_dummy(filename, duration):\n",
        "    \"\"\"Creates a dummy recording file.\"\"\"\n",
        "    print(f\"Creating a dummy recording file at {filename} for {duration} seconds.\")\n",
        "    try:\n",
        "        samplerate = 44100\n",
        "        data = np.random.rand(int(duration * samplerate)) * 0.1 # Little bit of noise\n",
        "        wav.write(filename, samplerate, data)\n",
        "        print(f\"Dummy recording saved to {filename}\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating dummy recording: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def combine_audio(beat_path, vocals_path):\n",
        "    \"\"\"Combines beat audio with recorded vocals.\"\"\"\n",
        "    if not os.path.exists(beat_path):\n",
        "        return f\"Error: Beat audio file not found at {beat_path}\"\n",
        "    if not os.path.exists(vocals_path):\n",
        "        return f\"Error: Vocal audio file not found at {vocals_path}\"\n",
        "\n",
        "    try:\n",
        "        beat_audio = AudioSegment.from_wav(beat_path)\n",
        "        vocal_audio = AudioSegment.from_wav(vocals_path)\n",
        "\n",
        "        # Ensure same frame rate\n",
        "        if beat_audio.frame_rate != vocal_audio.frame_rate:\n",
        "            print(f\"Warning: Mismatch in frame rates. Resampling vocal audio from {vocal_audio.frame_rate} to {beat_audio.frame_rate}\")\n",
        "            vocal_audio = vocal_audio.set_frame_rate(beat_audio.frame_rate)\n",
        "\n",
        "        # Ensure similar length\n",
        "        min_duration = min(len(beat_audio), len(vocal_audio))\n",
        "        beat_audio = beat_audio[:min_duration]\n",
        "        vocal_audio = vocal_audio[:min_duration]\n",
        "\n",
        "        # Overlay\n",
        "        combined_audio = beat_audio.overlay(vocal_audio)\n",
        "\n",
        "        export_dir = 'final_mixes'\n",
        "        os.makedirs(export_dir, exist_ok=True)\n",
        "        final_output_path = os.path.join(export_dir, 'final_performance_mix.wav')\n",
        "        combined_audio.export(final_output_path, format=\"wav\")\n",
        "\n",
        "        return final_output_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error combining audio files: {e}\")\n",
        "        return f\"Error combining audio files: {e}\"\n",
        "\n",
        "def create_soundwave_visualizer(y, sr, audio_duration_s):\n",
        "    \"\"\"Generates a static soundwave visualizer image.\"\"\"\n",
        "    if y is None or sr is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Calculate RMS energy over small frames\n",
        "        frame_length = 2048 # You can adjust this\n",
        "        hop_length = 512   # You can adjust this\n",
        "        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "        rms_times = librosa.times_like(rms, sr=sr, hop_length=hop_length)\n",
        "\n",
        "        # Set up the plot\n",
        "        fig, ax = plt.subplots(figsize=(12, 4))\n",
        "        ax.plot(rms_times, rms, lw=2)\n",
        "        ax.set_ylim(0, rms.max() * 1.1)\n",
        "        ax.set_xlim(0, audio_duration_s)\n",
        "        ax.set_xlabel(\"Time (s)\")\n",
        "        ax.set_ylabel(\"RMS Energy\")\n",
        "        ax.set_title(\"Soundwave Visualizer\")\n",
        "\n",
        "        # Save plot to a bytes buffer\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        plt.close(fig) # Close the figure to free memory\n",
        "\n",
        "        # Encode image to base64\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('ascii')\n",
        "\n",
        "        return image_base64\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating soundwave visualizer: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Flask Routes\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    global processed_audio_path, audio_analysis_results, final_generated_lyrics, audio_duration_s\n",
        "    processed_file = None\n",
        "    analysis_results_display = None\n",
        "    generated_lyrics_display = None\n",
        "    visualizer_image_base64 = None\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        if 'audio_file' in request.files and request.files['audio_file'].filename != '':\n",
        "            audio_file = request.files['audio_file']\n",
        "            processed_file = process_audio_input(audio_file)\n",
        "        elif 'audio_url' in request.form and request.form['audio_url'] != '':\n",
        "            audio_url = request.form['audio_url']\n",
        "            processed_file = process_audio_input(audio_url)\n",
        "        elif 'genre' in request.form: # Handle lyric generation request\n",
        "             user_genre = request.form.get('genre', 'Hip Hop')\n",
        "             user_theme = request.form.get('theme', 'general')\n",
        "             explicit_toggle = request.form.get('explicit', 'off') == 'on'\n",
        "             if audio_analysis_results:\n",
        "                 final_generated_lyrics = generate_lyrics(audio_analysis_results, user_genre, user_theme, explicit_toggle)\n",
        "                 generated_lyrics_display = final_generated_lyrics\n",
        "             else:\n",
        "                 generated_lyrics_display = \"Please upload/process audio first to generate lyrics.\"\n",
        "\n",
        "        if processed_file:\n",
        "            processed_audio_path = processed_file\n",
        "            audio_analysis_results = analyze_audio(processed_audio_path)\n",
        "            if audio_analysis_results:\n",
        "                analysis_results_display = f\"BPM: {audio_analysis_results['bpm']:.2f}, Mood: {audio_analysis_results['estimated_mood']}, Duration: {audio_analysis_results['duration']:.2f} seconds\"\n",
        "                # Generate visualizer image immediately after analysis\n",
        "                visualizer_image_base64 = create_soundwave_visualizer(audio_analysis_results.get('y'), audio_analysis_results.get('sr'), audio_analysis_results.get('duration', 0))\n",
        "\n",
        "\n",
        "    # Display existing data on GET requests or after POST\n",
        "    if audio_analysis_results:\n",
        "         analysis_results_display = f\"BPM: {audio_analysis_results['bpm']:.2f}, Mood: {audio_analysis_results['estimated_mood']}, Duration: {audio_analysis_results['duration']:.2f} seconds\"\n",
        "         # Regenerate visualizer on page load if analysis results exist\n",
        "         visualizer_image_base64 = create_soundwave_visualizer(audio_analysis_results.get('y'), audio_analysis_results.get('sr'), audio_analysis_results.get('duration', 0))\n",
        "\n",
        "    if final_generated_lyrics:\n",
        "        generated_lyrics_display = final_generated_lyrics\n",
        "\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Ai Lyrical Arsonist</title>\n",
        "    <h1>Ai Lyrical Arsonist</h1>\n",
        "\n",
        "    <h2>Upload an audio file or provide a URL</h2>\n",
        "    <form method=post enctype=multipart/form-data>\n",
        "      <p><input type=file name=audio_file>\n",
        "         <input type=submit value=Upload File>\n",
        "    </form>\n",
        "    <form method=post>\n",
        "      <p><input type=text name=audio_url placeholder=\"Enter URL\">\n",
        "         <input type=submit value=Download URL>\n",
        "    </form>\n",
        "\n",
        "    {% if processed_audio_path %}\n",
        "    <h2>Processed Audio:</h2>\n",
        "    <p>File ready for analysis and lyric generation.</p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if analysis_results_display %}\n",
        "    <h2>Audio Analysis Results:</h2>\n",
        "    <p>{{ analysis_results_display }}</p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if visualizer_image_base64 %}\n",
        "    <h2>Soundwave Visualizer:</h2>\n",
        "    <img src=\"data:image/png;base64,{{ visualizer_image_base64 }}\" alt=\"Soundwave Visualizer\">\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    <h2>Generate Lyrics</h2>\n",
        "    <form method=post>\n",
        "      <p>Genre: <input type=text name=genre value=\"Hip Hop\"></p>\n",
        "      <p>Theme: <input type=text name=theme value=\"general\"></p>\n",
        "      <p>Explicit: <input type=checkbox name=explicit value=\"on\"></p>\n",
        "      <input type=submit value=Generate Lyrics>\n",
        "    </form>\n",
        "\n",
        "    {% if generated_lyrics_display %}\n",
        "    <h2>Generated Lyrics:</h2>\n",
        "    <pre>{{ generated_lyrics_display }}</pre>\n",
        "    <p><a href=\"{{ url_for('edit_lyrics') }}\">Edit Lyrics</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if processed_audio_path and generated_lyrics_display %}\n",
        "    <h2>Playback and Recording</h2>\n",
        "    <p><a href=\"{{ url_for('playback') }}\">Start Playback and Sync (Text-based simulation)</a></p>\n",
        "     <p><a href=\"{{ url_for('record_page') }}\">Record Performance (Client-side required for real app)</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if processed_audio_path %}\n",
        "        {% set dummy_recording_path = 'user_recordings/user_performance.wav' %}\n",
        "        {% if os.path.exists(dummy_recording_path) %}\n",
        "            <h2>Combine Audio</h2>\n",
        "            <p><a href=\"{{ url_for('combine') }}\">Combine Beat and Vocals</a></p>\n",
        "        {% else %}\n",
        "             <h2>Record Performance</h2>\n",
        "             <p>Record your performance first to enable audio combining.</p>\n",
        "              <p><a href=\"{{ url_for('record_page') }}\">Record Performance (Client-side required for real app)</a></p>\n",
        "        {% endif %}\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    {% if os.path.exists('final_mixes/final_performance_mix.wav') %}\n",
        "    <h2>Final Mix</h2>\n",
        "    <p><a href=\"{{ url_for('download_mix') }}\">Download Final Mix</a></p>\n",
        "    {% endif %}\n",
        "\n",
        "\n",
        "    ''', processed_audio_path=processed_audio_path,\n",
        "         analysis_results_display=analysis_analysis_results,\n",
        "         generated_lyrics_display=generated_lyrics_display,\n",
        "         visualizer_image_base64=visualizer_image_base64,\n",
        "         os=os) # Pass os to check file existence\n",
        "\n",
        "@app.route('/edit_lyrics', methods=['GET', 'POST'])\n",
        "def edit_lyrics():\n",
        "    global final_generated_lyrics\n",
        "    if request.method == 'POST':\n",
        "        final_generated_lyrics = request.form.get('lyrics_textarea', '')\n",
        "        print(\"Lyrics edited and saved.\")\n",
        "        return redirect(url_for('index')) # Redirect back to the main page\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Edit Lyrics</title>\n",
        "    <h1>Edit Your Lyrics</h1>\n",
        "    <form method=post>\n",
        "      <textarea name=\"lyrics_textarea\" rows=\"20\" cols=\"80\">{{ lyrics }}</textarea><br><br>\n",
        "      <input type=submit value=Save>\n",
        "    </form>\n",
        "    <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "    ''', lyrics=final_generated_lyrics if final_generated_lyrics else \"No lyrics generated yet.\")\n",
        "\n",
        "\n",
        "@app.route('/playback')\n",
        "def playback():\n",
        "    global processed_audio_path, final_generated_lyrics\n",
        "\n",
        "    if not processed_audio_path or not os.path.exists(processed_audio_path):\n",
        "        return \"Error: Processed audio not available.\", 400\n",
        "    if not final_generated_lyrics:\n",
        "        return \"Error: Lyrics not generated yet.\", 400\n",
        "\n",
        "    # Simple lyric synchronization strategy (as before)\n",
        "    lyrics_lines = final_generated_lyrics.strip().split('\\n')\n",
        "    try:\n",
        "        audio_segment = AudioSegment.from_wav(processed_audio_path)\n",
        "        audio_duration_ms = len(audio_segment)\n",
        "        num_lines = len(lyrics_lines)\n",
        "        line_duration_ms = audio_duration_ms / num_lines if num_lines > 0 else 0\n",
        "    except Exception as e:\n",
        "        return f\"Error loading audio for playback: {e}\", 500\n",
        "\n",
        "    # This is a simplified text-based playback simulation for the notebook environment.\n",
        "    # A real web app would require client-side JavaScript for synchronized audio and lyric display.\n",
        "    playback_output = \"Starting playback and lyric sync...\\n\"\n",
        "    for i, line in enumerate(lyrics_lines):\n",
        "        playback_output += line + \"\\n\"\n",
        "        if i < len(lyrics_lines) - 1:\n",
        "             # Simulate timing (not real-time in a Flask response)\n",
        "             pass # In a real app, this timing is handled client-side\n",
        "\n",
        "    playback_output += \"Playback and lyric display completed.\\n\"\n",
        "\n",
        "    return render_template_string('''\n",
        "    <!doctype html>\n",
        "    <title>Playback and Sync</title>\n",
        "    <h1>Playback and Lyric Sync (Text-based simulation)</h1>\n",
        "    <pre>{{ output }}</pre>\n",
        "    <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "    ''', output=playback_output)\n",
        "\n",
        "\n",
        "@app.route('/record_page')\n",
        "def record_page():\n",
        "     # This route provides a page with instructions for recording.\n",
        "     # Actual recording is client-side in a real web app.\n",
        "     # For this demo, we'll create a dummy recording file when the user clicks 'Record Dummy'.\n",
        "     return render_template_string('''\n",
        "     <!doctype html>\n",
        "     <title>Record Performance</title>\n",
        "     <h1>Record Your Performance</h1>\n",
        "     <p>In a real web application, this page would use your microphone to record your vocals over the beat.</p>\n",
        "     <p>For this demonstration, you can create a dummy recording file to proceed with the combining step.</p>\n",
        "     <p><a href=\"{{ url_for('create_dummy_recording') }}\">Create Dummy Recording File</a></p>\n",
        "     <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "     ''')\n",
        "\n",
        "@app.route('/create_dummy_recording')\n",
        "def create_dummy_recording():\n",
        "    global audio_duration_s\n",
        "    dummy_recording_path = 'user_recordings/user_performance.wav'\n",
        "    # Create a dummy recording with the same duration as the processed audio\n",
        "    record_audio_dummy(dummy_recording_path, audio_duration_s if audio_duration_s > 0 else 10) # Default to 10 secs if duration is 0\n",
        "    return redirect(url_for('index'))\n",
        "\n",
        "\n",
        "@app.route('/combine')\n",
        "def combine():\n",
        "    global processed_audio_path\n",
        "    user_recording_path = 'user_recordings/user_performance.wav' # Assume this is the default recording file\n",
        "\n",
        "    if not processed_audio_path or not os.path.exists(processed_audio_path):\n",
        "        return \"Error: Processed beat audio not available.\", 400\n",
        "    if not os.path.exists(user_recording_path):\n",
        "        return f\"Error: User recording not found at {user_recording_path}. Please ensure a recording has been made (or a dummy file exists).\", 400\n",
        "\n",
        "    final_mix_path = combine_audio(processed_audio_path, user_recording_path)\n",
        "\n",
        "    if final_mix_path.startswith(\"Error\"):\n",
        "        return final_mix_path, 500\n",
        "    else:\n",
        "        return render_template_string('''\n",
        "        <!doctype html>\n",
        "        <title>Combine Audio</title>\n",
        "        <h1>Audio Combined!</h1>\n",
        "        <p>Final mix saved to: {{ final_mix_path }}</p>\n",
        "        <p><a href=\"{{ url_for('download_mix') }}\">Download Final Mix</a></p>\n",
        "        <p><a href=\"{{ url_for('index') }}\">Back to Home</a></p>\n",
        "        ''', final_mix_path=final_mix_path)\n",
        "\n",
        "@app.route('/download_mix')\n",
        "def download_mix():\n",
        "    final_mix_path = 'final_mixes/final_performance_mix.wav'\n",
        "    if os.path.exists(final_mix_path):\n",
        "        return send_file(final_mix_path, as_attachment=True)\n",
        "    else:\n",
        "        return \"Error: Final mix file not found.\", 404\n",
        "\n",
        "\n",
        "# To run the Flask app (for demonstration purposes)\n",
        "# Note: In a Colab environment, you might need to use ngrok or a similar service\n",
        "# to expose your local Flask server to the internet for testing in a browser.\n",
        "# For simple testing within Colab, you can use the built-in preview.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This will run the Flask development server\n",
        "    # debug=True allows for automatic reloading and helpful error pages\n",
        "    # Set host='0.0.0.0' to make the server accessible externally if needed (e.g., for ngrok)\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05a97f81"
      },
      "source": [
        "# Run the Flask app\n",
        "# This cell will start the Flask development server.\n",
        "# Note: In a Colab environment, you might need to use ngrok or a similar service\n",
        "# to expose your local Flask server to the internet for testing in a browser.\n",
        "# For simple testing within Colab, you can use the built-in preview.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This will run the Flask development server\n",
        "    # Set host='0.0.0.0' to make the server accessible externally if needed (e.g., for ngrok)\n",
        "    app.run(debug=True, host='0.0.0.0', port=5000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}